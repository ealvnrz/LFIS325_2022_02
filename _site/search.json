[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "LFIS325: Estadística para Ciencias Físicas",
    "section": "",
    "text": "Es un curso teórico/práctico de modalidad presencial, de nivel intermedio, cuya misión es introducir al estudiante a las principales herramientas de análisis. El curso está orientado a desarrollar en el estudiante la capacidad de transformar los datos de que dispone tanto para extraer información útil como también para facilitar las conclusiones. Aprenderá los conceptos de la teoría de la probabilidad y la inferencia estadística que se utilizan para interpretar datos experimentales. Abordará los problemas tanto desde una perspectiva teórica como con trabajos prácticos."
  },
  {
    "objectID": "index.html#softwares",
    "href": "index.html#softwares",
    "title": "LFIS325: Estadística para Ciencias Físicas",
    "section": "Softwares",
    "text": "Softwares\nPara la mayoría de las aplicaciones utilizaremos R, por lo que se sugiere utilizar un IDE como RStudio.\nPara la entrega de informes y talleres que requieran uso de programación, se recomienda el uso de Rmarkdown, Jupyter Notebook o \\(\\LaTeX\\) para la confección de documentos a entregar."
  },
  {
    "objectID": "pages/calendario.html",
    "href": "pages/calendario.html",
    "title": "Calendario",
    "section": "",
    "text": "Semana\nFecha\nPreparación\nPresentación\nMaterial adicional\nPrueba\nTrabajo Final\n\n\n\n\n1\n25-26/08\n📖\n🖥️\n📋\n\n\n\n\n2\n01-02/09\n📖\n🖥️\n📋\n\n\n\n\n3\n08-09/09\n📖\n🖥️\n📋\n\n\n\n\n4\n15-16/09\n📖\n🖥️\n📋\n\n\n\n\n5\n29-30/09\n📖\n🖥️\n📋\n📝\n\n\n\n6\n06-07/10\n📖\n🖥️\n📋\n\n\n\n\n7\n13-14/10\n📖\n🖥️\n📋\n\n\n\n\n8\n20-21/10\n📖\n🖥️\n📋\n\n\n\n\n9\n27-28/10\n📖\n🖥️\n📋\n\n\n\n\n10\n10-11/11\n📖\n🖥️\n📋\n\n\n\n\n11\n17-18/11\n📖\n🖥️\n📋\n\n\n\n\n12\n24-25/11\n📖\n🖥️\n📋\n\n\n\n\n13\n01-02/11\n📖\n🖥️\n📋\n\n📔\n\n\n14\n08-09/12\n📖\n🖥️\n📋\n📝\n\n\n\n15\n15-16/12\n📖\n🖥️\n📋\n\n\n\n\n16\n22-23/12\n📖\n🖥️\n📋\n\n📔"
  },
  {
    "objectID": "pages/evaluaciones.html",
    "href": "pages/evaluaciones.html",
    "title": "Evaluaciones",
    "section": "",
    "text": "Tipo de evaluación\nPorcentaje que corresponde\n\n\n\n\nEvaluaciones sumativas (2)\n50%\n\n\nPresentaciones\n30%\n\n\nTrabajo final\n20%"
  },
  {
    "objectID": "pages/programa.html",
    "href": "pages/programa.html",
    "title": "Programa del curso",
    "section": "",
    "text": "Introducción a la Estadística\n\nProceso Estadístico\nTipos de muestreo\nMedidas de tendencia muestral\nTablas de frecuencia\nTipos de gráficos\n\n\n\nProbabilidad en la ciencia\n\nDecisión y probabilidad\nTeorema de Bayes\nInferencia y probabilidad\nAnálisis de error simple\nUso de la estadística\n\n\n\nModelamiento de datos: Estimación de parámetros\n\nEl método de la probabilidad máxima\nMínimos cuadrados\nAnálisis Bayesiano\nModelamiento Monte Carlo\nModelo de modelos y combinación de conjunto de datos\n\n\n\nDetección y Búsqueda\n\nDetección\nCatálogos y efectos de selección\nEl límite de confusión\n\n\n\nEstadística en 1D y 2D\n\nTransformaciones de datos\nAnálisis de Fourier\nFiltrado\nCorrelacionamiento\nEstadística sobre una superficie\nRepresentación del cielo\nFunción correlación angular de dos puntos\nEl espectro de potencia angular\n\n\n\nCadenas de Markov Monte Carlo\n\nAlgoritmo de Metrópolis-Hastings\nComparación de modelos\nAplicaciones."
  },
  {
    "objectID": "pages/week1.html",
    "href": "pages/week1.html",
    "title": "Semana 1",
    "section": "",
    "text": "Leer el programa del curso"
  },
  {
    "objectID": "pages/week1.html#presentación",
    "href": "pages/week1.html#presentación",
    "title": "Semana 1",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week1.html#material-adicional",
    "href": "pages/week1.html#material-adicional",
    "title": "Semana 1",
    "section": "Material adicional",
    "text": "Material adicional\nSecciones 1.1 y 1.2 de Probability and Statistics for Engineering and the Sciences, 9th Edition."
  },
  {
    "objectID": "pages/week10.html#presentación",
    "href": "pages/week10.html#presentación",
    "title": "Semana 10",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week10.html#material-adicional",
    "href": "pages/week10.html#material-adicional",
    "title": "Semana 10",
    "section": "Material adicional",
    "text": "Material adicional"
  },
  {
    "objectID": "pages/week11.html#presentación",
    "href": "pages/week11.html#presentación",
    "title": "Semana 11",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week11.html#material-adicional",
    "href": "pages/week11.html#material-adicional",
    "title": "Semana 11",
    "section": "Material adicional",
    "text": "Material adicional"
  },
  {
    "objectID": "pages/week12.html#presentación",
    "href": "pages/week12.html#presentación",
    "title": "Semana 12",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week12.html#material-adicional",
    "href": "pages/week12.html#material-adicional",
    "title": "Semana 12",
    "section": "Material adicional",
    "text": "Material adicional"
  },
  {
    "objectID": "pages/week13.html#presentación",
    "href": "pages/week13.html#presentación",
    "title": "Semana 13",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week13.html#material-adicional",
    "href": "pages/week13.html#material-adicional",
    "title": "Semana 13",
    "section": "Material adicional",
    "text": "Material adicional"
  },
  {
    "objectID": "pages/week14.html#presentación",
    "href": "pages/week14.html#presentación",
    "title": "Semana 14",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week14.html#material-adicional",
    "href": "pages/week14.html#material-adicional",
    "title": "Semana 14",
    "section": "Material adicional",
    "text": "Material adicional"
  },
  {
    "objectID": "pages/week15.html#presentación",
    "href": "pages/week15.html#presentación",
    "title": "Semana 15",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week15.html#material-adicional",
    "href": "pages/week15.html#material-adicional",
    "title": "Semana 15",
    "section": "Material adicional",
    "text": "Material adicional"
  },
  {
    "objectID": "pages/week16.html#presentación",
    "href": "pages/week16.html#presentación",
    "title": "Semana 16",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week16.html#material-adicional",
    "href": "pages/week16.html#material-adicional",
    "title": "Semana 16",
    "section": "Material adicional",
    "text": "Material adicional"
  },
  {
    "objectID": "pages/week2.html",
    "href": "pages/week2.html",
    "title": "Semana 2",
    "section": "",
    "text": "Leer capítulo 1 de Probability and Statistics for Engineering and the Sciences, 9th Edition."
  },
  {
    "objectID": "pages/week2.html#presentación",
    "href": "pages/week2.html#presentación",
    "title": "Semana 2",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week2.html#material-adicional",
    "href": "pages/week2.html#material-adicional",
    "title": "Semana 2",
    "section": "Material adicional",
    "text": "Material adicional\nSecciones 1.3 y 1.4 de Probability and Statistics for Engineering and the Sciences, 9th Edition."
  },
  {
    "objectID": "pages/week3.html",
    "href": "pages/week3.html",
    "title": "Semana 3",
    "section": "",
    "text": "Leer capítulo 2 de Probability and Statistics for Engineering and the Sciences, 9th Edition."
  },
  {
    "objectID": "pages/week3.html#presentación",
    "href": "pages/week3.html#presentación",
    "title": "Semana 3",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week3.html#material-adicional",
    "href": "pages/week3.html#material-adicional",
    "title": "Semana 3",
    "section": "Material adicional",
    "text": "Material adicional\n\nGuía de ejercicios: estadística descriptiva\nGuía de ejercicios: cálculo de probabilidad\nGuía de ejercicios adicionales: estadística descriptiva"
  },
  {
    "objectID": "pages/week4.html#presentación",
    "href": "pages/week4.html#presentación",
    "title": "Semana 4",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week4.html#material-adicional",
    "href": "pages/week4.html#material-adicional",
    "title": "Semana 4",
    "section": "Material adicional",
    "text": "Material adicional\n\nPauta Prueba #1 2020\nPauta Prueba #1 2021"
  },
  {
    "objectID": "pages/week5.html#presentación",
    "href": "pages/week5.html#presentación",
    "title": "Semana 5",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week5.html#material-adicional",
    "href": "pages/week5.html#material-adicional",
    "title": "Semana 5",
    "section": "Material adicional",
    "text": "Material adicional\nPauta Prueba #1 2022"
  },
  {
    "objectID": "pages/week6.html",
    "href": "pages/week6.html",
    "title": "Semana 6",
    "section": "",
    "text": "Leer capítulo 3, Probability and Statistics for Engineering and the Sciences, 9th Edition."
  },
  {
    "objectID": "pages/week6.html#presentación",
    "href": "pages/week6.html#presentación",
    "title": "Semana 6",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week6.html#material-adicional",
    "href": "pages/week6.html#material-adicional",
    "title": "Semana 6",
    "section": "Material adicional",
    "text": "Material adicional\nLeer capítulo 4, Probability and Statistics for Engineering and the Sciences, 9th Edition."
  },
  {
    "objectID": "pages/week7.html",
    "href": "pages/week7.html",
    "title": "Semana 7",
    "section": "",
    "text": "Leer capítulo 5, Probability and Statistics for Engineering and the Sciences, 9th Edition."
  },
  {
    "objectID": "pages/week7.html#presentación",
    "href": "pages/week7.html#presentación",
    "title": "Semana 7",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week7.html#material-adicional",
    "href": "pages/week7.html#material-adicional",
    "title": "Semana 7",
    "section": "Material adicional",
    "text": "Material adicional\n\nLeer capítulo 2, Statistical data analysis, Glen Cowan.\nPauta Prueba #2 2020\nPauta Prueba #2 2021\nGuía de ejercicios: Variables aleatorias\nGuía de ejercicios: Variables aleatorias continuas\nGuía de ejercicios: Distribuciones\nGuía de ejercicios: Distribuciones continuas\nGuía de ejercicios: Variables aleatorias bivariadas"
  },
  {
    "objectID": "pages/week8.html#presentación",
    "href": "pages/week8.html#presentación",
    "title": "Semana 8",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week8.html#material-adicional",
    "href": "pages/week8.html#material-adicional",
    "title": "Semana 8",
    "section": "Material adicional",
    "text": "Material adicional"
  },
  {
    "objectID": "pages/week9.html#presentación",
    "href": "pages/week9.html#presentación",
    "title": "Semana 9",
    "section": "Presentación",
    "text": "Presentación\nVer presentación en pantalla completa"
  },
  {
    "objectID": "pages/week9.html#material-adicional",
    "href": "pages/week9.html#material-adicional",
    "title": "Semana 9",
    "section": "Material adicional",
    "text": "Material adicional"
  },
  {
    "objectID": "slides/lec_week1.html#descripción-del-curso",
    "href": "slides/lec_week1.html#descripción-del-curso",
    "title": "Estadística para ciencias físicas",
    "section": "Descripción del curso",
    "text": "Descripción del curso\nEs un curso teórico/práctico de modalidad presencial, de nivel intermedio, cuya misión es introducir al estudiante a las principales herramientas de análisis. El curso está orientado a desarrollar en el estudiante la capacidad de transformar los datos de que dispone tanto para extraer información útil como también para facilitar las conclusiones. Aprenderá los conceptos de la teoría de la probabilidad y la inferencia estadística que se utilizan para interpretar datos experimentales. Abordará los problemas tanto desde una perspectiva teórica como con trabajos prácticos."
  },
  {
    "objectID": "slides/lec_week1.html#horario-de-clases",
    "href": "slides/lec_week1.html#horario-de-clases",
    "title": "Estadística para ciencias físicas",
    "section": "Horario de clases",
    "text": "Horario de clases\n\n\n\n\nDía\nHorario\nLugar\n\n\n\n\nCátedra #1\nJueves\n08:30 am - 10:00 am\nJuan Mouat\n\n\nCátedra #2\nViernes\n14:30 pm - 16:00 pm\nJuan Mouat\n\n\nCátedra #3\nViernes\n16:15 pm - 17:45 pm\nJuan Mouat\n\n\n\nPágina del curso\nUtilizaremos el Aula Virtual/Google Classroom y el sitio https://lfis325-2022-02.netlify.com/. Ambas páginas tendrán la misma información, sin embargo, para efectos de entrega de informes, el medio oficial será el Aula Virtual/Google Classroom."
  },
  {
    "objectID": "slides/lec_week1.html#softwares",
    "href": "slides/lec_week1.html#softwares",
    "title": "Estadística para ciencias físicas",
    "section": "Softwares",
    "text": "Softwares\nPara la mayoría de las aplicaciones utilizaremos R, por lo que se sugiere utilizar un IDE como RStudio.\nPara la entrega de informes y talleres que requieran uso de programación, se recomienda el uso de Rmarkdown, Jupyter Notebook o \\(\\LaTeX\\) para la confección de documentos a entregar."
  },
  {
    "objectID": "slides/lec_week1.html#bibliografía",
    "href": "slides/lec_week1.html#bibliografía",
    "title": "Estadística para ciencias físicas",
    "section": "Bibliografía",
    "text": "Bibliografía\nLa bibliografía principal del curso es:\n\n\n\n\n\n\nStatistical Data Analysis, Glen Cowan.\n\n\n\n\n\n\n\nPractical Statistics for Astronomers, J.V. Wall, C.R. Jenkins\n\n\n\n\n\n\n\nProbability and Statistics for Engineering and the Sciences, 9th Edition.Jay L. Devore"
  },
  {
    "objectID": "slides/lec_week1.html#introducción-a-la-estadística",
    "href": "slides/lec_week1.html#introducción-a-la-estadística",
    "title": "Estadística para ciencias físicas",
    "section": "Introducción a la Estadística",
    "text": "Introducción a la Estadística\n\nProceso Estadístico\nTipos de muestreo\nMedidas de tendencia muestral\nTablas de frecuencia\nTipos de gráficos"
  },
  {
    "objectID": "slides/lec_week1.html#probabilidad-en-la-ciencia",
    "href": "slides/lec_week1.html#probabilidad-en-la-ciencia",
    "title": "Estadística para ciencias físicas",
    "section": "Probabilidad en la ciencia",
    "text": "Probabilidad en la ciencia\n\nDecisión y probabilidad\nTeorema de Bayes\nInferencia y probabilidad\nAnálisis de error simple\nUso de la estadística"
  },
  {
    "objectID": "slides/lec_week1.html#modelamiento-de-datos-estimación-de-parámetros",
    "href": "slides/lec_week1.html#modelamiento-de-datos-estimación-de-parámetros",
    "title": "Estadística para ciencias físicas",
    "section": "Modelamiento de datos: Estimación de parámetros",
    "text": "Modelamiento de datos: Estimación de parámetros\n\nEl método de la probabilidad máxima\nMínimos cuadrados\nAnálisis Bayesiano\nModelamiento Monte Carlo\nModelo de modelos y combinación de conjunto de datos"
  },
  {
    "objectID": "slides/lec_week1.html#detección-y-búsqueda",
    "href": "slides/lec_week1.html#detección-y-búsqueda",
    "title": "Estadística para ciencias físicas",
    "section": "Detección y Búsqueda",
    "text": "Detección y Búsqueda\n\nDetección\nCatálogos y efectos de selección\nEl límite de confusión"
  },
  {
    "objectID": "slides/lec_week1.html#estadística-en-1d-y-2d",
    "href": "slides/lec_week1.html#estadística-en-1d-y-2d",
    "title": "Estadística para ciencias físicas",
    "section": "Estadística en 1D y 2D",
    "text": "Estadística en 1D y 2D\n\nTransformaciones de datos\nAnálisis de Fourier\nFiltrado\nCorrelacionamiento\nEstadística sobre una superficie\nRepresentación del cielo\nFunción correlación angular de dos puntos\nEl espectro de potencia angular"
  },
  {
    "objectID": "slides/lec_week1.html#cadenas-de-markov-monte-carlo",
    "href": "slides/lec_week1.html#cadenas-de-markov-monte-carlo",
    "title": "Estadística para ciencias físicas",
    "section": "Cadenas de Markov Monte Carlo",
    "text": "Cadenas de Markov Monte Carlo\n\nAlgoritmo de Metrópolis-Hastings\nComparación de modelos\nAplicaciones."
  },
  {
    "objectID": "slides/lec_week1.html#ponderaciones",
    "href": "slides/lec_week1.html#ponderaciones",
    "title": "Estadística para ciencias físicas",
    "section": "Ponderaciones",
    "text": "Ponderaciones\nLa metodología de evaluación es la siguiente:\n\n\n\nTipo de evaluación\nPorcentaje que corresponde\n\n\n\n\nEvaluaciones sumativas (2)\n50%\n\n\nPresentaciones\n30%\n\n\nTrabajo final\n20%"
  },
  {
    "objectID": "slides/lec_week1.html#metodología-del-curso",
    "href": "slides/lec_week1.html#metodología-del-curso",
    "title": "Estadística para ciencias físicas",
    "section": "Metodología del curso",
    "text": "Metodología del curso\n\nAntes de cada clase, se mandará una lectura de preparación para la sesión\nEl enfoque principal será teórico, pero sin dejar de lado las aplicaciones\nSe pondrá a disposición material adicional para estudiar:\n\nEjemplos y ejercicios teóricos\nCódigos\n\nEl curso será mayoritariamente autocontenido, pero requiere al menos conocimiento básico cálculo y programación."
  },
  {
    "objectID": "slides/lec_week1.html#proceso-estadístico",
    "href": "slides/lec_week1.html#proceso-estadístico",
    "title": "Estadística para ciencias físicas",
    "section": "Proceso estadístico",
    "text": "Proceso estadístico\nLa estadística es la ciencia encargada de la descripción, organización, presentación de datos y además la obtención de conclusiones basadas en los datos experimentales; a esto le llamamos inferencia, la cual es inductiva debido a que se proyecta de lo específico hacia lo general.\nAl ser una ciencia, esta se rige al método científico."
  },
  {
    "objectID": "slides/lec_week1.html#diagrama-del-proceso-estadístico",
    "href": "slides/lec_week1.html#diagrama-del-proceso-estadístico",
    "title": "Estadística para ciencias físicas",
    "section": "Diagrama del proceso estadístico",
    "text": "Diagrama del proceso estadístico"
  },
  {
    "objectID": "slides/lec_week1.html#por-qué-el-uso-de-la-estadística-en-física",
    "href": "slides/lec_week1.html#por-qué-el-uso-de-la-estadística-en-física",
    "title": "Estadística para ciencias físicas",
    "section": "¿Por qué el uso de la estadística en física?",
    "text": "¿Por qué el uso de la estadística en física?\n\nCuantificación del error: Errores propios y externos, ¿Qué significan?.\n¿Cómo pueden nuestros datos ser utilizados de la mejor manera posible? o ¿Pueden ser usados?.\nCorrelaciones, test de hipótesis y modelación: ¿Como se procede?.\nMuestras incompletas, datos de un experimento que no puede ser replicado ¿Cómo se trabajo con este tipo de datos?.\nLa presentación de datos y conclusión siempre vienen -inherentemente- en términos estadísticos.\nEl proceso de decisión no puede ser realizado sin una metodología, sin importar que tan bueno sea el experimento."
  },
  {
    "objectID": "slides/lec_week1.html#procedimiento-de-un-experimento",
    "href": "slides/lec_week1.html#procedimiento-de-un-experimento",
    "title": "Estadística para ciencias físicas",
    "section": "Procedimiento de un experimento",
    "text": "Procedimiento de un experimento\n\nObservar: Registrar u obtener los datos.\nReducir: Limpiar los datos para eliminar efectos experimentales: corrección flat-field, calibración, etc.\nAnalizar: Obtener los números desde una base de datos limpia: intensidades, posiciones, etcétera. A partir de esta información, producir indicadores que permitan comparar o modelar. Estos indicadores son llamados estadísticos y determinan el diseño de experimentos.\nConclusión: Llevar a cabo un procedimiento para llegar a una conclusión. Test de hipótesis; correlación, modelos, etc.\nReflexión: ¿Qué se aprendió? ¿Es la decisión viable? ¿Fue inesperada? ¿En qué paso del experimiento se debe examinar para verificar? ¿Qué es necesario para confirmar un resultado inesperado? ¿Cómo se debe realizar el siguiente experimento? ¿Se extenderá la hipótesis realizada o se sugerirá una nueva hipótesis?"
  },
  {
    "objectID": "slides/lec_week1.html#diagrama-de-una-muestra",
    "href": "slides/lec_week1.html#diagrama-de-una-muestra",
    "title": "Estadística para ciencias físicas",
    "section": "Diagrama de una muestra",
    "text": "Diagrama de una muestra"
  },
  {
    "objectID": "slides/lec_week1.html#tipos-de-muestreo",
    "href": "slides/lec_week1.html#tipos-de-muestreo",
    "title": "Estadística para ciencias físicas",
    "section": "Tipos de muestreo",
    "text": "Tipos de muestreo\n\nMuestreo no Probabilístico: Los resultados obtenidos sólo representan las características de los elementos muestrados y no de la población\n\nMuestreo por conveniencia\nMuestreo consecutivo\nMuestreo por cuotas\nMuestreo de bola de nieve. (Muestreo en cadena).\n\nMuestreo Probabilístico: Cada uno de los elementos de la población de interés, o población objetivo, tiene una probabilidad conocida (frecuentemente igual) de ser elegidos en la muestra."
  },
  {
    "objectID": "slides/lec_week1.html#muestreo-aleatorio-simple-y-sistemático",
    "href": "slides/lec_week1.html#muestreo-aleatorio-simple-y-sistemático",
    "title": "Estadística para ciencias físicas",
    "section": "Muestreo aleatorio simple y sistemático",
    "text": "Muestreo aleatorio simple y sistemático\n\nMuestreo Aleatorio Simple: Los elementos se escogen en forma individual y al azar de la totalidad de la población, es decir, se escogen sin ningún privilegio y cada uno posee la misma probabilidad de formar parte de la muestra en cada una de las posibles muestras.\nMuestreo Aleatorio Sistemático: Existe un plan de muestreo al azar, en la cual se eligen los elementos de la población a intervalos uniformes, a partir de un listado (ordenado), tal como elegir cada \\(k-\\)ésimo elemento después de un arranque aleatorio."
  },
  {
    "objectID": "slides/lec_week1.html#muestreo-estratificado",
    "href": "slides/lec_week1.html#muestreo-estratificado",
    "title": "Estadística para ciencias físicas",
    "section": "Muestreo estratificado",
    "text": "Muestreo estratificado\n\nMuestreo Aleatorio Estratificado: La característica que se está midiendo en la población objetivo, presenta mucha dispersión en grupos identificados, por lo tanto, lo primero que se debe hacer es estratificar los elementos de la población en subgrupos y excluyentes de acuerdo al comportamiento que presenta la característica dentro de estos grupos.\n\n\n\n\n\n\n\nPosterior a la clasificación de los elementos de la población en grupos, se obtiene por separado una muestra aleatoria simple o sistemática de cada estrato."
  },
  {
    "objectID": "slides/lec_week1.html#tipos-de-variable",
    "href": "slides/lec_week1.html#tipos-de-variable",
    "title": "Estadística para ciencias físicas",
    "section": "Tipos de variable",
    "text": "Tipos de variable\n\nVariables Cualitativas: Cuando los elementos de una población son clasificados en categorías o clases excluyentes, se habla de variables cualitativas. Ejemplos: estado civil, lugar de procedencia, marca de artículos, etc.\nVariables Cuantitativas (o Numéricas): Si los posibles valores para los elementos de una población, son cantidades o números, se habla de variables cuantitativas. Ejemplos: kms por litro de gasolina de un auto, temperatura, duración de un examen, etc.\n\nDiscretas: Se habla de variables discretas, cuando el conjunto de valores posibles es finito o infinito numerable. Ejemplos: Cantidad de crías por camada, número de alumnos por carrera, etc.\nContinuas: Son aquellas que pueden asumir infinitos valores. Ejemplos: sueldo de una persona, tiempo que tarda un animal en alcanzar un peso previamente determinado, etc."
  },
  {
    "objectID": "slides/lec_week1.html#escalas-de-medición",
    "href": "slides/lec_week1.html#escalas-de-medición",
    "title": "Estadística para ciencias físicas",
    "section": "Escalas de medición",
    "text": "Escalas de medición\n\nEscalas de Medición para variables cualitativas:\n\nNominal: Es aquella escala en donde las categorías (o los posibles valores de la variable), no pueden ser ordenadas en un sentido de magnitud. Ejemplos: colores, profesión, etc.\nOrdinal: Cuando las categorías admiten una ordenación (no alfabética), se habla de escala ordinal. Ejemplo: Nivel Socio-económico (alto, medio o bajo), sistema de evaluación cualitativa (insuficiente, suficiente, bueno, muy bueno), etc.\n\nEscalas de Medición para variables cuantitativas:\n\nIntervalar: Son aquellas que poseen un punto de referencia (o cero) relativo, en el sentido de que si se cambia de unidad de medición, el punto de referencia difiere entre una unidad de medida y otra. Ejemplo: temperatura (Celcius - Fahrenheit).\nRazón: Son aquellas que poseen un cero absoluto (es decir, único). Incluso permiten hacer comparaciones por cocientes. Ejemplo: Peso de una persona, distancias, etc."
  },
  {
    "objectID": "slides/lec_week1.html#organización-de-los-datos",
    "href": "slides/lec_week1.html#organización-de-los-datos",
    "title": "Estadística para ciencias físicas",
    "section": "Organización de los datos",
    "text": "Organización de los datos\nLa organización de los datos trata de acomodar éstos para que puedan revelar sus características informativas fundamentales y de esta manera simplificar los análisis para la obtención de conclusiones.\nEl uso de frecuencia es más natural en datos cualitativos o discretos, pues en estos casos es sencillo contar el número de veces que aparece un mismo dato en la población (muestra) de éstos, en este caso se habla de tabla de frecuencia no agrupadas.\nSin Embargo, cuando se trabaja con datos cuantitativos en escala continua, es muy posible que exista un conjunto de números distintos lo suficientemente grande, como para hacer impracticable lo anterior, en este último caso se procede a crear agrupaciones convenientes para los datos observados, en este caso se habla de tabla de frecuencia agrupadas."
  },
  {
    "objectID": "slides/lec_week1.html#tabla-de-frecuencia",
    "href": "slides/lec_week1.html#tabla-de-frecuencia",
    "title": "Estadística para ciencias físicas",
    "section": "Tabla de frecuencia",
    "text": "Tabla de frecuencia\nEn las tablas de frecuencia cada categoría tiene una frecuencia observada, este cálculo es siempre posible en datos cualitativos, sin embargo, si la cantidad de categorías es grande, deja de ser un resumen adecuado para los datos.\nLas respuestas observadas en la población (muestra), se denominarán clases, y se simbolizan por: \\(C_1,C_2,\\dots, C_k\\) donde \\(k\\) es la cantidad de categorías (respuestas) distintas."
  },
  {
    "objectID": "slides/lec_week1.html#frecuencia-absoluta",
    "href": "slides/lec_week1.html#frecuencia-absoluta",
    "title": "Estadística para ciencias físicas",
    "section": "Frecuencia absoluta",
    "text": "Frecuencia absoluta\nSe llama frecuencia absoluta de la clase \\(C_i\\), al número de elementos de la población (muestra) que pertenecen a la clase \\(C_i\\). Este número lo denotaremos por \\(n_i\\) y cumplen la propiedad:\n\\[\\sum_{i=1}^{k} n_i =n\\]\nEn donde \\(n\\) es el tamaño de la población o muestra, según sea el caso."
  },
  {
    "objectID": "slides/lec_week1.html#frecuencia-relativa",
    "href": "slides/lec_week1.html#frecuencia-relativa",
    "title": "Estadística para ciencias físicas",
    "section": "Frecuencia relativa",
    "text": "Frecuencia relativa\nSe llama frecuencia relativa de la clase \\(C_i\\), a la cantidad de elementos en la población (muestra) que pertenecen a la clase \\(C_i\\), relativo al total de elementos en la población (muestra). Este número lo denotaremos por \\(f_i\\) y cumplen la propiedad:\n\\[f_i=\\dfrac{n_i}{n} \\Rightarrow \\sum_{i=1}^{k} f_i = \\sum_{i=1}^{k}\\dfrac{n_i}{n} = 1\\]"
  },
  {
    "objectID": "slides/lec_week1.html#frecuencia-absoluta-acumulada",
    "href": "slides/lec_week1.html#frecuencia-absoluta-acumulada",
    "title": "Estadística para ciencias físicas",
    "section": "Frecuencia absoluta acumulada",
    "text": "Frecuencia absoluta acumulada\nSe llama frecuencia absoluta acumulada hasta la clase \\(C_i\\), al número total de elementos en la población (muestra) que pertenecen a las clases \\(C_1,C_2,\\dots,C_i\\). Este número lo denotaremos por \\(N_i\\) y cumplen la propiedad:\n\\[N_i=n_1+n_2+\\dots+n_i=\\sum_{j=1}^{i}n_j, \\hspace{10pt} j=1,2,\\dots,i, \\hspace{10pt} i=1,2,\\dots,k\\] y,\n\\[N_k=n_1+n_2+\\dots+n_i+\\dots+n_k=n\\]"
  },
  {
    "objectID": "slides/lec_week1.html#frecuencia-relativa-acumulada",
    "href": "slides/lec_week1.html#frecuencia-relativa-acumulada",
    "title": "Estadística para ciencias físicas",
    "section": "Frecuencia relativa acumulada",
    "text": "Frecuencia relativa acumulada\nSe llama frecuencia relativa acumulada hasta la clase \\(C_i\\), a la cantidad de elementos en la población (muestra) que pertenecen a las clases \\(C_1,C_2,\\dots,C_i\\), con respecto al total de elementos en la población (muestra). Este número lo denotaremos por \\(F_i\\) y cumplen la propiedad:\n\\[F_i=f_1+f_2+\\dots+f_i=\\sum_{j=1}^{i}f_j, \\hspace{10pt} j=1,2,\\dots,i, \\hspace{10pt} i=1,2,\\dots,k\\]"
  },
  {
    "objectID": "slides/lec_week1.html#ejemplo-enunciado",
    "href": "slides/lec_week1.html#ejemplo-enunciado",
    "title": "Estadística para ciencias físicas",
    "section": "Ejemplo: enunciado",
    "text": "Ejemplo: enunciado\nEn un conjunto de resultados experimentales, se desea determinar la clasificación de los resultados obtenidos. Estos son clasificados como: Malos (M), Regulares (R), Buenos (B) y Excelentes (E). Los datos son:\n\n\n\nB\nR\nB\nE\nE\nE\nM\nB\nE\nR\n\n\nR\nM\nM\nR\nR\nM\nR\nB\nB\nB\n\n\nB\nB\nE\nB\nB\nB\nE\nB\nE\nR\n\n\nE\nM\nB\nB\nE\nB\nB\nB\nB\nB\n\n\nM\nR\nM\nB\nB\nB\nB\nE\nM\nR"
  },
  {
    "objectID": "slides/lec_week1.html#ejemplo-respuesta",
    "href": "slides/lec_week1.html#ejemplo-respuesta",
    "title": "Estadística para ciencias físicas",
    "section": "Ejemplo: respuesta",
    "text": "Ejemplo: respuesta\n\n\n\n\nFrecuencias\n\nFrecuencias\nAcumuladas\n\n\n\n\nClasificación\nAbsoluta\nRelativa\nAbsoluta\nRelativa\n\n\nMalo\n8\n16%\n8\n16%\n\n\nRegular\n9\n18%\n17\n34%\n\n\nBuenos\n23\n46%\n40\n80%\n\n\nExcelentes\n10\n20%\n50\n100%"
  },
  {
    "objectID": "slides/lec_week1.html#tablas-para-variables-continuas",
    "href": "slides/lec_week1.html#tablas-para-variables-continuas",
    "title": "Estadística para ciencias físicas",
    "section": "Tablas para variables continuas",
    "text": "Tablas para variables continuas\nEn variables continuas, la organización de datos es un poco más compleja: se dividen los datos en \\(k\\) grupos o segmentos disjuntos. Estos grupos representan las clases y se determina la frecuencia de datos asociado a cada grupo, conformando una tabla de frecuencia agrupada.\nEn este tipo de datos las clases están compuestas por intervalos, luego es necesario buscar un representante de la frecuencia asociada a este intervalo , el cual se conoce como marca de clase. Es común utilizar como marca de clase al valor medio del segmento (intervalo)."
  },
  {
    "objectID": "slides/lec_week1.html#construcción-de-la-tabla-de-frecuencia",
    "href": "slides/lec_week1.html#construcción-de-la-tabla-de-frecuencia",
    "title": "Estadística para ciencias físicas",
    "section": "Construcción de la tabla de frecuencia",
    "text": "Construcción de la tabla de frecuencia\nEn la construcción de una tabla de frecuencia, lo primero que se tiene que tener claro es la cantidad de segmentos (intervalos) a considerar. Lo más común es utilizar como una primera aproximación la regla de Sturges.\n\nRegla de Sturges: El número de clases \\(k= 3,3 * \\log(n)+1\\), donde \\(n\\) es la cantidad de datos que se desea organizar.\nAmplitud: Para determinar la amplitud de las clases \\(a\\), se debe calcular el rango \\(R_D\\), que es la diferencia entre el dato mayor (\\(\\max x_i\\)) y el dato menor (\\(\\min x_i\\)). También es necesario determinar \\(u\\), la unidad mínima de conteo de los datos. Luego, la amplitud estará dada por:\n\n\n\\[ a=\\dfrac{R_D +u}{k}\\]"
  },
  {
    "objectID": "slides/lec_week1.html#rango-de-la-tabla",
    "href": "slides/lec_week1.html#rango-de-la-tabla",
    "title": "Estadística para ciencias físicas",
    "section": "Rango de la tabla",
    "text": "Rango de la tabla\nUna vez determinada la amplitud \\(a\\), se procede a determinar el rango de la tabla \\(R_T\\), que es la multiplicación entre la cantidad de clases que se están utilizando y la amplitud. Para determinar los límites teóricos de las clases, se comienza con el límite inferior de la primera clase (\\(LI_1\\)), el cual se calcula como:\n\\[LI_1=\\min x_i - \\dfrac{D}{2}\\]\nDonde la diferencia \\(D=R_T-R_D\\), en el caso que el último dígito de \\(D\\) no sea par, se realiza un ajuste conveniente.\nPosteriormente, se suma la amplitud a \\(LI_1\\) obteniéndose el limite superior de esta clase (\\(LS_1\\)), el que también será el límite inferior de la segunda clase, \\(LI_2=LS_1\\). Este último se considera abierto para su clase y cerrado para la segunda clase, luego para los siguientes intervalos se realiza el mismo procedimiento anterior."
  },
  {
    "objectID": "slides/lec_week1.html#tabla-general",
    "href": "slides/lec_week1.html#tabla-general",
    "title": "Estadística para ciencias físicas",
    "section": "Tabla general",
    "text": "Tabla general\n\n\n\n\nFrecuencias\n\nFrecuencias\nAcumuladas\n\n\n\n\nClases\nAbsoluta\nRelativa\nAbsoluta\nRelativa\n\n\n\\([LI_1-LS_1[\\)\n\\(n_1\\)\n\\(f_1\\)\n\\(N_1\\)\n\\(F_1\\)\n\n\n\\([LI_2-LS_2[\\)\n\\(n_2\\)\n\\(f_2\\)\n\\(N_2\\)\n\\(F_2\\)\n\n\n\\([LI_3-LS_3[\\)\n\\(n_3\\)\n\\(f_3\\)\n\\(N_3\\)\n\\(F_3\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\([LI_k-LS_k[\\)\n\\(n_k\\)\n\\(f_k\\)\n\\(N_k\\)\n\\(F_k\\)"
  },
  {
    "objectID": "slides/lec_week2.html#media-aritmética",
    "href": "slides/lec_week2.html#media-aritmética",
    "title": "Estadística descriptiva",
    "section": "Media aritmética",
    "text": "Media aritmética\nSe define como el cociente de la suma de todos los valores entre el número total de valores. Las expresiones para cálculo de la media de una población y de una muestra son, respectivamente:\n\\[\\mu = \\dfrac{\\sum_{i=1}^{N}X_i}{N}, \\hspace{20pt} \\overline{x} = \\dfrac{\\sum_{i=1}^{n} X_i}{n}\\]\nCuando se tiene a disposición sólo los datos agrupados, se utiliza el punto medio de cada clase como aproximación de todos los valores contenidos en ella. El punto medio o marca de clase se representa por \\(m_i\\), en donde el subíndice \\(i\\) indica la clase \\(i-\\)ésima, y se utiliza \\(n_i\\) para representar la frecuencia absoluta observada en la clase respectiva. En tal caso, las expresiones son:\n\\[\\mu = \\dfrac{\\sum_{i=1}^{k} n_i m_i}{N}, \\hspace{20pt} \\overline{x} = \\dfrac{\\sum_{i=1}^{k} n_i m_i}{n}\\]"
  },
  {
    "objectID": "slides/lec_week2.html#mediana",
    "href": "slides/lec_week2.html#mediana",
    "title": "Estadística descriptiva",
    "section": "Mediana",
    "text": "Mediana\nEs el valor que ocupa el lugar central de estos cuando se ordenan en orden de magnitud. Para conjunto de datos, con un número par de elementos, la mediana se calcula como el promedio de los valores centrales. En caso de trabajar con datos dispersos, la expresión para determinar la posición de la mediana en el conjunto (ordenado) es:\n\\[Me=\\begin{cases}\nX_{\\left(\\dfrac{n+1}{2}\\right)}, &\\text{Si }n\\text{ es impar} \\\\\n\\dfrac{1}{2}\\left(X_{\\left(\\dfrac{n}{2}\\right)} + X_{\\left(\\dfrac{n}{2}+1\\right)}\\right), &\\text{Si }n\\text{ es par}\n\\end{cases}\\]"
  },
  {
    "objectID": "slides/lec_week2.html#mediana-datos-agrupados",
    "href": "slides/lec_week2.html#mediana-datos-agrupados",
    "title": "Estadística descriptiva",
    "section": "Mediana: datos agrupados",
    "text": "Mediana: datos agrupados\nPara datos agrupados, en primer lugar es necesario determinar la clase que contiene el valor de la mediana, para después determinar la posición de la mediana dentro de la clase mediante interpolación. La clase que contiene la mediana es la primera clase cuya frecuencia acumulada es mayor o igual a la mitad de los datos. Una vez que se identifica esta clase, se determina el valor interpolado de la mediana, empleando la siguiente expresión:\n\\[Me=LI_i+ \\left( \\dfrac{\\dfrac{n}{2}-N_{i-1}}{n_i}\\right)a_i\\]\nEn donde \\(LI_i\\) es límite inferior de la clase que contiene a la mediana, \\(n\\) el número total de observaciones, \\(a_i\\) la amplitud de clase, \\(N_{i-1}\\) la frecuencia acumulada anterior a la clase que contiene la mediana y \\(n_i\\) el número de observaciones de la clase que contiene la mediana."
  },
  {
    "objectID": "slides/lec_week2.html#moda",
    "href": "slides/lec_week2.html#moda",
    "title": "Estadística descriptiva",
    "section": "Moda",
    "text": "Moda\nSe define como el valor o clase que se presenta con mayor frecuencia. Para datos agrupados, se utiliza interpolación dentro de la clase modal, de acuerdo a la siguiente expresión:\n\\[Mo=LI_i+ \\left(\\dfrac{d_1}{d_1+d_2} \\right)a_i\\] en donde,\n\n\\(LI_i\\) es el límite inferior de la clase que contiene la moda.\n\\(d_1\\) es la diferencia entre la frecuencia de la clase modal y la frecuencia de la clase que le precede.\n\\(d_2\\) es la diferencia entre la frecuencia de la clase modal y la frecuencia de la clase que le sigue.\n\\(a_i\\) es la amplitud de clase."
  },
  {
    "objectID": "slides/lec_week2.html#cuantiles",
    "href": "slides/lec_week2.html#cuantiles",
    "title": "Estadística descriptiva",
    "section": "Cuantiles",
    "text": "Cuantiles\nSon medidas de posición que dividen los datos en grupos bajo los cuales se encuentra una determinada proporción de éstos, por lo se requiere que los datos se encuentren en al menos escala ordinal.\n\nCuartil: \\(Q_{i}=X_{\\left(\\dfrac{i(n+1)}{4}\\right)}, \\hspace{20pt} i:1,2,\\dots,4\\)\nQuintil: \\(K_{i}=X_{\\left(\\dfrac{i(n+1)}{5}\\right)}, \\hspace{20pt} i:1,2,\\dots,5\\)\nDecil: \\(D_{i}=X_{\\left(\\dfrac{i(n+1)}{10}\\right)}, \\hspace{20pt} i:1,2,\\dots,10\\)\nPercentil: \\(P_{i}=X_{\\left(\\dfrac{i(n+1)}{100}\\right)}, \\hspace{20pt} i:1,2,\\dots,100\\)"
  },
  {
    "objectID": "slides/lec_week2.html#cuantiles-datos-agrupados",
    "href": "slides/lec_week2.html#cuantiles-datos-agrupados",
    "title": "Estadística descriptiva",
    "section": "Cuantiles: datos agrupados",
    "text": "Cuantiles: datos agrupados\nPara datos agrupados, la fórmula se modifica de acuerdo con el punto fraccionario de interés. Para utilizar esta expresión modificada, en primer lugar se determina la clase que contiene el punto de interés, de acuerdo con las frecuencias acumuladas, y después se lleva a cabo una interpolación como en el caso anterior de la mediana."
  },
  {
    "objectID": "slides/lec_week2.html#interpolación",
    "href": "slides/lec_week2.html#interpolación",
    "title": "Estadística descriptiva",
    "section": "Interpolación",
    "text": "Interpolación\nEn este caso se observa que \\(y=\\mathbf{y}, x=P_{78}, x_2 - x_1= LS-LI=a\\) y \\(y_2 - y_1 = N_i - N_{i-1}=n_i\\)\nLuego despejando \\(x=P_{78}\\), se obtiene una expresión para el cálculo de percentiles en datos agrupados:\n\\[x=P_{78}=x_1+\\left( \\dfrac{y-y_1}{y_2 - y_1} \\right)(x_2 - x_1)=LI+\\left(\\dfrac{y- N_{i-1}}{n_i}\\right)a\\]\npero \\(y\\) no es otra cosa que \\(\\dfrac{n \\times j}{100}\\), donde \\(j\\) es el percentil \\(j-\\)ésimo. Por lo que podemos generalizar la ecuación anterior como:\n\\[P_j=LI+\\left(\\dfrac{\\dfrac{n\\times j}{100}-N_{i-1}}{n_i}\\right)a=LI+\\left(\\dfrac{\\dfrac{j}{100}-F_{i-1}}{f_i}\\right)a\\]"
  },
  {
    "objectID": "slides/lec_week2.html#ejemplo",
    "href": "slides/lec_week2.html#ejemplo",
    "title": "Estadística descriptiva",
    "section": "Ejemplo",
    "text": "Ejemplo\nLa siguiente tabla resume los tiempos de espera antes de obtener ciertos resultados experimentales.\n\nCalcular el percentil 80"
  },
  {
    "objectID": "slides/lec_week2.html#rango",
    "href": "slides/lec_week2.html#rango",
    "title": "Estadística descriptiva",
    "section": "Rango",
    "text": "Rango\nEs la diferencia entre el mayor y menor valor del conjunto de datos.\n\\[R= \\begin{cases}\\max x_i - \\min x_i,  &\\text{datos dispersos} \\\\ LS_k -LI_1,  &\\text{datos agrupados} \\end{cases}\\]"
  },
  {
    "objectID": "slides/lec_week2.html#desviación-media",
    "href": "slides/lec_week2.html#desviación-media",
    "title": "Estadística descriptiva",
    "section": "Desviación media",
    "text": "Desviación media\nEs la media (promedio) del valor absoluto de la diferencia entre cada uno de los datos y el promedio del grupo.\n\\[DM= \\begin{cases}\\sum_{i=1}^{n}\\dfrac{|x_i- \\overline{x}|}{n}, &\\text{datos dispersos}\\\\\\sum_{i=1}^{k} f_i |m_i - \\overline{x}|,&\\text{datos agrupados}\\end{cases}\\]"
  },
  {
    "objectID": "slides/lec_week2.html#varianza",
    "href": "slides/lec_week2.html#varianza",
    "title": "Estadística descriptiva",
    "section": "Varianza",
    "text": "Varianza\n\\((V[X],\\sigma^2)\\) La varianza es similar a la desviación media porque se basa en la diferencia entre cada uno de los valores del conjunto de datos y la media del grupo. Su fórmula es, para su cálculo poblacional y muestral, respectivamente:\n\\[V[X]=\\sigma^2=\\sum_{i=1}^{N} \\dfrac{(x_i-\\mu)^2}{N}\\]\n\\[S^2=\\sum_{i=1}^{n} \\dfrac{(x_i-\\overline{x})^2}{n-1}\\]"
  },
  {
    "objectID": "slides/lec_week2.html#desviación-estándar-o-típica",
    "href": "slides/lec_week2.html#desviación-estándar-o-típica",
    "title": "Estadística descriptiva",
    "section": "Desviación estándar o típica",
    "text": "Desviación estándar o típica\nSe utiliza con mayor frecuencia la raíz cuadrada de la varianza, representada mediante la letra griega \\(\\sigma\\) para el caso poblacional y \\(S\\) para una muestra:\n\\[\\sigma=\\sqrt{V[X]}\\]\n\\[S=\\sqrt{S^2}\\]"
  },
  {
    "objectID": "slides/lec_week2.html#coeficiente-de-variación",
    "href": "slides/lec_week2.html#coeficiente-de-variación",
    "title": "Estadística descriptiva",
    "section": "Coeficiente de variación",
    "text": "Coeficiente de variación\nRelación entre la desviación estándar y su media. Tiene por fórmula, para su cálculo poblacional y muestral, respectivamente:\n\\[CV=\\dfrac{\\sigma}{\\mu}\\]\n\\[CV=\\dfrac{S}{\\overline{x}}\\]\nRepresenta la desviación estándar como proporción (o porcentaje) de la media, por lo que es de gran utilidad al comparar dos poblaciones o muestras, pues no posee unidades lo que elimina el efecto de la magnitud de las variables medidas."
  },
  {
    "objectID": "slides/lec_week2.html#rango-intercuartil",
    "href": "slides/lec_week2.html#rango-intercuartil",
    "title": "Estadística descriptiva",
    "section": "Rango intercuartil",
    "text": "Rango intercuartil\nEs la diferencia entre los percentiles 75 y 25, esto es RIQ (IQR)\\(= Q_3 - Q_1\\).\n\nRepresenta el 50% central de la población"
  },
  {
    "objectID": "slides/lec_week2.html#histograma",
    "href": "slides/lec_week2.html#histograma",
    "title": "Estadística descriptiva",
    "section": "Histograma",
    "text": "Histograma"
  },
  {
    "objectID": "slides/lec_week2.html#ojiva",
    "href": "slides/lec_week2.html#ojiva",
    "title": "Estadística descriptiva",
    "section": "Ojiva",
    "text": "Ojiva"
  },
  {
    "objectID": "slides/lec_week2.html#diagrama-de-caja-box-plot",
    "href": "slides/lec_week2.html#diagrama-de-caja-box-plot",
    "title": "Estadística descriptiva",
    "section": "Diagrama de caja / box-plot",
    "text": "Diagrama de caja / box-plot"
  },
  {
    "objectID": "slides/lec_week2.html#construcción-box-plot",
    "href": "slides/lec_week2.html#construcción-box-plot",
    "title": "Estadística descriptiva",
    "section": "Construcción box-plot",
    "text": "Construcción box-plot\n\nCalcular: Mediana, Cuartil 1 y 3 \\((Q_{1},Q_{3})\\)\nCalcular Rango Intercuartil (RIQ/IQR): \\(RIQ=Q_{3}-Q_{1}\\)\nCalcular bigotes interiores (superiores e inferiores):\n\nBigote inferior: \\(\\max (Q_{1}-1,5* RIQ, x_{1})\\)\nBigote superior: \\(\\min (Q_{3}+1,5* RIQ, x_{n})\\)\n\nCalcular bigotes exteriores (superiores e inferiores):\n\nBigote inferior: \\(Q_{1}-3* RIQ\\)\nBigote superior: \\(Q_{3}+3* RIQ\\)\n\nMarcar datos outliers:\n\nObservaciones entre bigote interior y exterior, se consideran sospechosos de ser outliers.\nObservaciones pasados los bigotes exteriores son outliers."
  },
  {
    "objectID": "slides/lec_week2.html#ejercicio",
    "href": "slides/lec_week2.html#ejercicio",
    "title": "Estadística descriptiva",
    "section": "Ejercicio",
    "text": "Ejercicio\nDatos:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(7,12\\)\n\\(7,89\\)\n\\(10,12\\)\n\\(8,88\\)\n\\(10,02\\)\n\\(9,91\\)\n\\(9,95\\)\n\\(9,90\\)\n\n\n\n\n\\(10,23\\)\n\\(9,12\\)\n\\(9,99\\)\n\\(12,40\\)\n\\(8,65\\)\n\\(10,05\\)\n\\(10,50\\)\n\\(9,87\\)\n\n\n\\(8,54\\)\n\\(9,72\\)\n\\(11,09\\)\n\\(11,52\\)\n\\(12,30\\)\n\\(11,53\\)\n\\(16,40\\)\n\\(13,24\\)\n\n\n\n\nRealizar un diagrama de caja"
  },
  {
    "objectID": "slides/lec_week3.html#escuelas-de-probabilidad",
    "href": "slides/lec_week3.html#escuelas-de-probabilidad",
    "title": "Probabilidades",
    "section": "Escuelas de probabilidad",
    "text": "Escuelas de probabilidad\n\nEnfoque clásico\nEnfoque frecuentista\nEnfoque bayesiano"
  },
  {
    "objectID": "slides/lec_week3.html#enfoque-clásico",
    "href": "slides/lec_week3.html#enfoque-clásico",
    "title": "Probabilidades",
    "section": "Enfoque clásico",
    "text": "Enfoque clásico\nEste enfoque también llamado enfoque apriori tiene por característica principal la asignación igualitaria de una medida de ocurrencia para un resultado de un experimento aleatorio (experimento equiprobable).\n\nEsta asignación de probabilidad se determina antes de observar los resultados experimentales.\n\n\n\n¿Algún ejemplo?"
  },
  {
    "objectID": "slides/lec_week3.html#enfoque-frecuentista",
    "href": "slides/lec_week3.html#enfoque-frecuentista",
    "title": "Probabilidades",
    "section": "Enfoque frecuentista",
    "text": "Enfoque frecuentista\nEste enfoque también llamado enfoque empírico, determina la medida de ocurrencia con base en la proporción de veces que ocurre un resultado favorable en un determinado número de observaciones o experimentos. Este enfoque no asigna probabilidades a priori a los posibles resultados de un experimento aleatorio.\n\n\n¿Algún ejemplo?"
  },
  {
    "objectID": "slides/lec_week3.html#enfoque-bayesiano",
    "href": "slides/lec_week3.html#enfoque-bayesiano",
    "title": "Probabilidades",
    "section": "Enfoque bayesiano",
    "text": "Enfoque bayesiano\nEste enfoque también llamado enfoque subjetivo, determina la medida de ocurrencia en base a una expectativa razonable basado en el conocimiento del investigador.\nEl enfoque bayesiano es particularmente útil cuando se tiene poca información del experimento, y este puede ser realizado para actualizador mis probabilidades, esto debido a que cada realización del experimento aleatorio me otorgará información adicional para determinar correctamente mis probabilidades."
  },
  {
    "objectID": "slides/lec_week3.html#principio-de-multiplicación",
    "href": "slides/lec_week3.html#principio-de-multiplicación",
    "title": "Probabilidades",
    "section": "Principio de multiplicación",
    "text": "Principio de multiplicación\nSupongamos que un procedimiento \\(1\\), puede hacerse de \\(n_1\\) maneras. Supongamos que un segundo procedimiento \\(2\\), se puede hacer de \\(n_2\\) maneras. También supongamos que cada una de las maneras de efectuar 1 puede ser seguida por cualquiera de las \\(n_2\\) de efectuar 2.\nEntonces el procedimiento que consta de \\(1\\) seguido por \\(2\\) se puede hacer de \\(n_1 \\times n_2\\) maneras. De igual manera podemos generalizar lo anterior a cualquier número de procedimientos."
  },
  {
    "objectID": "slides/lec_week3.html#principio-de-adición",
    "href": "slides/lec_week3.html#principio-de-adición",
    "title": "Probabilidades",
    "section": "Principio de adición",
    "text": "Principio de adición\nSupongamos que un procedimiento \\(1\\), se puede hacerse de \\(n_1\\) maneras, y que un segundo procedimiento \\(2\\), se puede hacer de \\(n_2\\) maneras. Supongamos además que no es posible que ambos procedimientos, 1 y 2, se realicen. Entonces el número de maneras como se puede hacer el procedimiento 1 ó 2 es de \\(n_1 + n_2\\).\n\nFactorial: Sea \\(n \\in \\mathbb{N}\\), entonces se define \\(n\\) factorial como \\(n \\times (n-1) \\times (n-2) \\times \\dots \\times 1\\), y se simboliza por \\(n!\\) Empleado en situaciones donde una vez seleccionado un elemento, éste puede ser nuevamente seleccionado.\n\n\nEjemplo\nConsidere un grupo de personas conformado por 15 hombres y 10 mujeres. Se eligen 3 personas al azar, la primera será la presidente de la comisión, la segunda vicepresidente y la tercera secretario. ¿De cuantas formas se puede conformar la comisión?"
  },
  {
    "objectID": "slides/lec_week3.html#permutación",
    "href": "slides/lec_week3.html#permutación",
    "title": "Probabilidades",
    "section": "Permutación",
    "text": "Permutación\nSe define la permutación de \\(r\\) elementos sobre \\(n\\) como el número de arreglos distintos que se pueden hacer con \\(r\\) elementos de un total de \\(n\\), importando el orden en el que salen los elementos, se simboliza por:\n\\[P_{r}^{n}=\\dfrac{n!}{(n-r)!}\\]\n\nEjemplo\nUn directorio compuesto por: Presidente, Secretario y Tesorero se debe elegir de un total de 10 candidatos. ¿Cuántos directorios diferentes se pueden conformar?\n\\[P_{3}^{10}=\\dfrac{10!}{(10-3)!}=\\dfrac{10!}{7!}=720\\]"
  },
  {
    "objectID": "slides/lec_week3.html#combinatoria",
    "href": "slides/lec_week3.html#combinatoria",
    "title": "Probabilidades",
    "section": "Combinatoria",
    "text": "Combinatoria\nSe define la combinatoria de \\(r\\) elementos sobre \\(n\\) como el número de arreglos distintos que se pueden hacer con \\(r\\) elementos de un total de \\(n\\) sin importar el orden en que son asignados. Esta expresión se anota por:\n\\[C_{r}^{n}={{n}\\choose{r}}=\\dfrac{n!}{r!(n-r)!}\\]\n\nEjemplo\nPara formar un comité se van a elegir a tres personas de un total de 10. El número de grupos diferentes de tres personas que podrían elegirse, sin importar el orden en el que cada uno de los grupos está dado por:\n\\[C_{3}^{10}=\\dfrac{10!}{3!(10-3)!}=\\dfrac{10!}{3!7!}=\\dfrac{720}{6}=120\\]"
  },
  {
    "objectID": "slides/lec_week3.html#clasificación-del-espacio-muestral",
    "href": "slides/lec_week3.html#clasificación-del-espacio-muestral",
    "title": "Probabilidades",
    "section": "Clasificación del espacio muestral",
    "text": "Clasificación del espacio muestral\n\nDiscreto\n\nNumerable: Finito o Infinito.\n\nContinuo\n\nNo numerable: Acotado o No acotado."
  },
  {
    "objectID": "slides/lec_week3.html#definición-formal-de-probabilidad",
    "href": "slides/lec_week3.html#definición-formal-de-probabilidad",
    "title": "Probabilidades",
    "section": "Definición formal de probabilidad",
    "text": "Definición formal de probabilidad\nEl par \\((\\Omega,\\Sigma)\\) se dice espacio medible, y la función \\(\\mathbb{P}:\\Sigma \\rightarrow \\mathbb{R}^{+}\\), es una medida de probabilidad si satisface:\n\n\\(0\\leq \\mathbb{P}[A] \\leq 1, \\forall A \\in \\Sigma\\)\n\\(\\mathbb{P}[\\Omega]=1\\)\nDados \\(\\displaystyle A_1,A_2,\\dots \\in \\Sigma \\Rightarrow \\mathbb{P}\\left[ \\bigcup_{i=1}^{n} A_n \\right] = \\sum_{i=1}^{n} \\mathbb{P}[A_i], \\hspace{5pt} \\forall i\\)"
  },
  {
    "objectID": "slides/lec_week3.html#algunas-propiedades",
    "href": "slides/lec_week3.html#algunas-propiedades",
    "title": "Probabilidades",
    "section": "Algunas propiedades",
    "text": "Algunas propiedades\n\n\\(\\mathbb{P}[A]+\\mathbb{P}[A^c]=\\mathbb{P}[\\Omega]\\)\n\\(\\mathbb{P}[\\phi]=1-\\mathbb{P}[\\phi^c]=1-\\mathbb{P}[\\Omega]=0\\)\n\\(\\mathbb{P}[A \\cup B]=\\mathbb{P}[A]+\\mathbb{P}[B] - \\mathbb{P}[A\\cap B]\\) . Si este último término \\((\\mathbb{P}[A\\cap B])\\) es cero, se dice que \\(A\\) y \\(B\\) son eventos mutuamente excluyentes.\n\\(\\mathbb{P}[A-B]=\\mathbb{P}[A\\cap B^c]\\)\n\\(\\mathbb{P}[A \\cap B]=\\mathbb{P}[A]\\mathbb{P}[B]\\). Si \\(A\\) y \\(B\\) son independientes."
  },
  {
    "objectID": "slides/lec_week3.html#ejercicio",
    "href": "slides/lec_week3.html#ejercicio",
    "title": "Probabilidades",
    "section": "Ejercicio",
    "text": "Ejercicio\nSea A el evento en el cual un hombre vivirá 10 años más y sea B el evento en el cual su esposa viva 10 años más. Supongamos que \\(\\mathbb{P}(A)=\\frac{1}{4}\\) y \\(\\mathbb{P}(B)=\\frac{1}{3}\\). Supongamos que A y B son eventos independientes, encuentre la probabilidad de que en 10 años:\n\nAmbos estén vivos.\nAl menos uno esté vivo.\nNinguno esté vivo.\nSolamente la esposa esté viva"
  },
  {
    "objectID": "slides/lec_week3.html#probabilidades-clásicas",
    "href": "slides/lec_week3.html#probabilidades-clásicas",
    "title": "Probabilidades",
    "section": "Probabilidades clásicas",
    "text": "Probabilidades clásicas\nEste planteamiento probabilista establece que los eventos del espacio muestral sean expresados de la forma más elemental posible, con el fin de poder aceptar la posibilidad de que cada posible resultado sea igualmente posible.\n\\[\\mathbb{P}[A]=\\dfrac{\\#A}{\\#\\Omega}\\]\n\nEjemplo\nConsidere que se tienen 10 sacos de semillas. Se sabe que 4 son de una variedad y el resto de otra. Un cliente compra 3 sacos. ¿Cuál es la probabilidad de que los sacos sean de las dos variedades?\n\n\\(A:{ \\text{Los sacos comprados son de las dos variedades} }\\)\n\\[\\mathbb{P}[A]=\\dfrac{\\#A}{\\#\\Omega}=\\dfrac{ C_{1}^{4} \\times C_{2}^{6} +C_{2}^{4} \\times C_{1}^{6} }{C_{3}^{10}}\\]"
  },
  {
    "objectID": "slides/lec_week3.html#probabilidades-condicionales",
    "href": "slides/lec_week3.html#probabilidades-condicionales",
    "title": "Probabilidades",
    "section": "Probabilidades condicionales",
    "text": "Probabilidades condicionales\nEl concepto de probabilidad condicional se emplea para redefinir el cálculo de probabilidad de ocurrencia de un evento dada cierta condición (o información). Lo anotamos por:\n\\[\\mathbb{P}[B | A]=\\dfrac{\\mathbb{P}[B \\cap A]}{\\mathbb{P}[A]}\\]\nLo anterior, mide la probabilidad de que el evento \\(B\\) ocurra dado que el evento \\(A\\) ocurrió. Notar que si los eventos \\(A\\) y \\(B\\) son independientes se tiene:\n\\[\\mathbb{P}[B|A]=\\dfrac{\\mathbb{P}[B]\\mathbb{P}[A]}{\\mathbb{P}[A]}=\\mathbb{P}[B]\\]\nPor lo que, en palabras, si los eventos son independientes, la probabilidad condicional se reduce a la probabilidad simple."
  },
  {
    "objectID": "slides/lec_week3.html#regla-multiplicativa",
    "href": "slides/lec_week3.html#regla-multiplicativa",
    "title": "Probabilidades",
    "section": "Regla multiplicativa",
    "text": "Regla multiplicativa\nSe refiere a la determinación de la probabilidad de ocurrencia conjunta de dos o más eventos. Para el caso de dos eventos, se tiene:\n\\[\\mathbb{P}[A\\cap B]=\\mathbb{P}[A]\\mathbb{P}[B|A]\\]\nEn el caso de tres eventos, se tiene:\n\\[\\mathbb{P}[A \\cap B \\cap C]=\\mathbb{P}[A] \\mathbb{P}[B|A] \\mathbb{P}[C| (A \\cap B)]\\]"
  },
  {
    "objectID": "slides/lec_week3.html#diagrama-de-árbol",
    "href": "slides/lec_week3.html#diagrama-de-árbol",
    "title": "Probabilidades",
    "section": "Diagrama de árbol",
    "text": "Diagrama de árbol\nLos diagramas de árbol son particularmente útiles para ilustrar los posibles eventos asociados con observaciones o ensayos secuenciales."
  },
  {
    "objectID": "slides/lec_week3.html#regla-de-bayes",
    "href": "slides/lec_week3.html#regla-de-bayes",
    "title": "Probabilidades",
    "section": "Regla de Bayes",
    "text": "Regla de Bayes\nLa regla de Bayes permite actualizar ciertas probabilidades a priori para transformarse en probabilidades posteriori de un evento (experimento). La importancia de la regla de Bayes consiste en que se aplica en contexto de eventos secuenciales y además, de que proporciona la base para determinar la probabilidad condicional de un evento a la luz de un evento especifico que ha ocurrido.\n\\[\\mathbb{P}[A|B]=\\dfrac{\\mathbb{P}[A\\cap B]}{\\mathbb{P}[B]}=\\dfrac{\\mathbb{P}[A]\\mathbb{P}[B|A]}{\\mathbb{P}[A]\\mathbb{P}[B|A]+\\mathbb{P}[A^c]\\mathbb{P}[B|A^c]}\\]\n\nEjemplo\n\nUn fabricante posee dos máquinas que producen el mismo artículo. Se sabe que una de ella (A) produce un \\(5\\%\\) de defectuosos y la otra (B) un \\(3\\%\\). Por otra parte el \\(60\\%\\) de las unidades es producido por la máquina A.\n\nDefina sucesos e identifique las probabilidades.\nSi el artículo es no defectuoso. ¿Cuál es la probabilidad que el artículo provenga de la máquina A?"
  },
  {
    "objectID": "slides/lec_week3.html#ejemplo-5",
    "href": "slides/lec_week3.html#ejemplo-5",
    "title": "Probabilidades",
    "section": "Ejemplo",
    "text": "Ejemplo\nUn grupo de estudiantes se inscribió en dos asignaturas, A y B. De los resultados se observa que el 40% aprobó A. El 45% aprobó al menos una asignatura. De los que aprobaron A, el 37.5% aprobó B. Se elige un alumno al azar, calcule la probabilidad que:\n\nHaya aprobado ambas asignaturas.\nHaya aprobado B.\nNo haya aprobado ni A ni B"
  },
  {
    "objectID": "slides/lec_week3.html#desarrollo-ejemplo",
    "href": "slides/lec_week3.html#desarrollo-ejemplo",
    "title": "Probabilidades",
    "section": "Desarrollo ejemplo",
    "text": "Desarrollo ejemplo\nDefiniendo los eventos:\n\\[A: \\text{ El alumno aprobó la asignatura }A \\quad B: \\text{ El alumno aprobó la asignatura } B\\]\npor enunciado sabemos que:\n\\[\\mathbb{P}(A) = 0.4 \\hspace{15pt} \\mathbb{P}(A\\cup B)=0.45 \\hspace{15pt} \\mathbb{P}(B\\vert A)=0.375\\]\nPor lo que:\n\nHaya aprobado ambas asignaturas.\n\n\n\\[\\mathbb{P}(A \\cap B)= \\mathbb{P}(B\\vert A)* \\mathbb{P}(A)=0.375 * 0.4=0.15\\]\n\nHaya aprobado \\(B\\).\n\n\n\n\\[\\mathbb{P}(B)=\\mathbb{P}(A\\cup B)-\\mathbb{P}(A)+\\mathbb{P}(A\\cap B)=0.45-0.4+0.15= 0.2\\]\n\nNo haya aprobado ni \\(A\\) ni \\(B\\)\n\n\n\n\\[\\mathbb{P}(A^c \\cap B^c)=\\mathbb{P}((A \\cup B)^c)=1-\\mathbb{P}(A \\cup B)=1-0.45\\]"
  },
  {
    "objectID": "slides/lec_week3.html#pregunta-tipo-prueba",
    "href": "slides/lec_week3.html#pregunta-tipo-prueba",
    "title": "Probabilidades",
    "section": "Pregunta tipo prueba",
    "text": "Pregunta tipo prueba\nUna persona esta interesada en invertir su dinero en acciones en el mercado bursátil nacional. Estudios estadísticos indican que las preferencias por las distintas acciones están representadas por las del tipo A y tipo B. Además, el 45% de preferencias son por las acciones del tipo A. Si la acción es de tipo A, la probabilidad de tener una rentabilidad positiva es de 0.7. Si la acción es de tipo B, la probabilidad de tener una rentabilidad positiva es de 0.6.\n\nDefina sucesos e identifique las probabilidades.\n¿Cuál es la probabilidad de tener una rentabilidad positiva?\nSi la rentabilidad es negativa, ¿Cuál es la probabilidad que no se haya invertido en acciones del tipo A?"
  },
  {
    "objectID": "slides/lec_week3.html#desarrollo-pregunta-tipo-prueba",
    "href": "slides/lec_week3.html#desarrollo-pregunta-tipo-prueba",
    "title": "Probabilidades",
    "section": "Desarrollo pregunta tipo prueba",
    "text": "Desarrollo pregunta tipo prueba\nDefiniendo eventos como:\n\n\\(A: \\text{ La persona invierte en acciones de tipo }A\\)\n\\(B: \\text{ La persona invierte en acciones de tipo }B\\)\n\\(R: \\text{ Se obtiene rentabilidad positiva tras invertir}\\)\n\n\nAsí,\n\\[\\mathbb{P}(A)=0.45 \\hspace{15pt} \\mathbb{P}(R\\vert A)=0.7 \\hspace{15pt} \\mathbb{P}(R\\vert B)=0.6\\]\n\n\n¿Cuál es la probabilidad de tener una rentabilidad positiva?\n\n\nPor regla multiplicativa se tiene que:\n\\[\\mathbb{P}(R)=\\mathbb{P}(A)*\\mathbb{P}(R\\vert A)+\\mathbb{P}(B)*\\mathbb{P}(R\\vert B)\\]\nreemplazando, tenemos que:\n\\[\\mathbb{P}(R)=0.45*0.7+0.55*0.6=0.645\\]"
  },
  {
    "objectID": "slides/lec_week3.html#continuación-desarrollo",
    "href": "slides/lec_week3.html#continuación-desarrollo",
    "title": "Probabilidades",
    "section": "Continuación desarrollo",
    "text": "Continuación desarrollo\nSi la rentabilidad es negativa, ¿Cuál es la probabilidad que no se haya invertido en acciones del tipo A?\nPor enunciado se sabe que \\(\\displaystyle \\mathbb{P}(R\\vert B)=0.6 \\Rightarrow \\mathbb{P}(R^{c}\\vert B)=0.4= \\dfrac{\\mathbb{P}(R^{c}\\cap B)}{\\mathbb{P}(B)}\\), pero\n\\[\\mathbb{P}(B)=0.55 \\Rightarrow \\mathbb{P}(R^{c}\\cap B)= 0.4 * 0.55 = 0.22\\]\nNos piden \\(\\mathbb{P}(B\\vert R^{c})=\\dfrac{\\mathbb{P}(B\\cap R^{c})}{\\mathbb{P}(R^{c})}=\\dfrac{0.22}{(1-\\mathbb{P}(R))}\\).\nPor ítem anterior sabemos que \\(\\mathbb{P}(R)=0.645 \\Rightarrow \\mathbb{P}(R^{c})=1-0.645\\).\nReemplazando,\n\\[\\dfrac{\\mathbb{P}(B\\cap R^{c})}{\\mathbb{P}(R^{c})}=\\dfrac{0.22}{0.355}\\approx 0.62\\]"
  },
  {
    "objectID": "slides/lec_week6.html#tipos-de-variables-aleatorias",
    "href": "slides/lec_week6.html#tipos-de-variables-aleatorias",
    "title": "Variables aleatorias",
    "section": "Tipos de variables aleatorias",
    "text": "Tipos de variables aleatorias\nSe dice que \\(X\\) es una Variable Aleatoria si es una función que toma valores en probabilidad, es decir, no se puede predecir con certeza sus resultados.\nUna variable aleatoria es siempre cuantitativa y se puede clasificar en los siguientes grupos:\n\\[X(\\omega)\n\\begin{cases}\n\\text{Discreto}\n\\begin{cases}\n\\text{Finito}\\\\\n\\text{Infinito}\n\\end{cases}\\\\\n\\text{Continuo}\n\\begin{cases}\n\\text{Acotados}\\\\\n\\text{No Acotados}\n\\end{cases}\n\\end{cases}\n\\]"
  },
  {
    "objectID": "slides/lec_week6.html#variables-aleatorias-discretas",
    "href": "slides/lec_week6.html#variables-aleatorias-discretas",
    "title": "Variables aleatorias",
    "section": "Variables aleatorias discretas",
    "text": "Variables aleatorias discretas\nUna variable aleatoria \\(X\\) es llamada discreta si:\n\nSu soporte \\(R_X\\) es un conjunto numerable.\nExiste una función \\(p_X:\\mathbb{R}\\rightarrow [0,1]\\), llamada la función de masa de probabilidad de \\(X\\), tal que, para cualquier \\(x\\in \\mathbb{R}\\):\n\n\n\\[p_X(x)\\begin{cases} \\mathbb{P}(X=x) \\quad &\\text{si } x\\in R_X\\\\ 0 \\quad &\\text{si } x\\notin R_X\\end{cases}\\]\n\n\nEsta función tiene dos características principales:\n\nno-negatividad: \\(p_X(x)\\geq 0\\) para cualquier \\(x\\in \\mathbb{R}\\).\nSuma sobre su soporte es 1: \\(\\sum_{x\\in R_X}p_X(x)=1\\)"
  },
  {
    "objectID": "slides/lec_week6.html#variables-aleatorias-continuas",
    "href": "slides/lec_week6.html#variables-aleatorias-continuas",
    "title": "Variables aleatorias",
    "section": "Variables aleatorias continuas",
    "text": "Variables aleatorias continuas\nUna variable aleatoria \\(X\\) es llamada continua si:\n\nSu soporte \\(R_X\\) es un conjunto no-numerable.\nExiste una función \\(f_X:\\mathbb{R}\\rightarrow [0,1]\\), llamada función de densidad de probabilidad de \\(X\\), tal que, para cualquier intervalo \\([a,b]\\subseteq \\mathbb{R}\\):\n\n\n\\[\\mathbb{P}(X\\in [a,b])=\\int_{a}^{b}f_X(x)dx\\]\n\n\nEsta función tiene dos características principales:\n\nno-negatividad: \\(f_X(x)\\geq 0\\) para cualquier \\(x\\in \\mathbb{R}\\).\nIntegral sobre \\(\\mathbb{R}\\) es 1: \\(\\int_{-\\infty}^{\\infty} f_X(x)dx=1\\)."
  },
  {
    "objectID": "slides/lec_week6.html#variable-aleatoria-discreta-finita",
    "href": "slides/lec_week6.html#variable-aleatoria-discreta-finita",
    "title": "Variables aleatorias",
    "section": "Variable Aleatoria Discreta Finita",
    "text": "Variable Aleatoria Discreta Finita\n\\(\\varepsilon\\): Experimento Aleatorio: Lanzamiento de un dado cinco veces.\n\\[\\downarrow\\]\n\\(\\Omega\\): Espacio Muestral: Resultados (par o impar) del primer hasta el quinto lanzamiento.\n\\[\\left\\lbrace (I,I,I,I,I);(P,I,I,P,P);\\cdots\\right\\rbrace\\]\n\\[\\downarrow\\]\n\\(X:\\) Número de pares en 5 lanzamientos.\n\\[\\downarrow\\]\n\\[\\mathbb{R}_{X}:\\left\\lbrace 0,1,2,3,4,5\\right\\rbrace\\]"
  },
  {
    "objectID": "slides/lec_week6.html#variable-aleatoria-discreta-infinita",
    "href": "slides/lec_week6.html#variable-aleatoria-discreta-infinita",
    "title": "Variables aleatorias",
    "section": "Variable Aleatoria Discreta Infinita",
    "text": "Variable Aleatoria Discreta Infinita\n\\(\\varepsilon\\): Experimento Aleatorio: Lanzamiento de un dado hasta que ocurra el primer par.\n\\[\\downarrow\\]\n\\(\\Omega\\): Espacio Muestral: Resultados (par o impar) del lanzamiento hasta que ocurra el primer par. \\[\\left\\lbrace (P);(I,P);(I,I,P)\\cdots\\right\\rbrace\\]\n\\[\\downarrow \\]\n\\(X:\\) Número lanzamientos hasta que ocurra el primer par\n\\[\\downarrow\\]\n\\[\\mathbb{R}_{X}:\\left\\lbrace 1,2,3,4,5,\\cdots\\right\\rbrace\\]"
  },
  {
    "objectID": "slides/lec_week6.html#variable-aleatoria-continua-no-acotada",
    "href": "slides/lec_week6.html#variable-aleatoria-continua-no-acotada",
    "title": "Variables aleatorias",
    "section": "Variable Aleatoria Continua No Acotada",
    "text": "Variable Aleatoria Continua No Acotada\n\\(\\varepsilon\\): Experimento Aleatorio: Lanzamiento de un dado hasta que se obtenga un número par.\n\\[\\downarrow\\]\n\\(\\Omega\\): Espacio Muestral: Tiempo necesario hasta que el resultado del lanzamiento del dado sea par. \\[\\mathbb{R}^{+}:[0,\\infty[\\]\n\\[\\downarrow\\]\n\\(X:\\) Tiempo hasta la ocurrencia del primer resultado par.\n\\[\\downarrow\\]\n\\[\\mathbb{R}_{X}:\\mathbb{R}^{+}:[0,\\infty[\\]"
  },
  {
    "objectID": "slides/lec_week6.html#función-de-distribución",
    "href": "slides/lec_week6.html#función-de-distribución",
    "title": "Variables aleatorias",
    "section": "Función de distribución",
    "text": "Función de distribución\nLas variables aleatorias son usualmente caracterizadas en términos de sus funciones de distribución.\n\nSea \\(X\\) una variable aleatoria. La función de distribución de \\(X\\) es una función \\(F_X:\\mathbb{R}\\rightarrow [0,1]\\) tal que:\n\\[F_X(x)=\\mathbb{P}(X\\leq x), \\forall x\\in \\mathbb{R}\\]\n\n\nSi conocemos la función de distribución de una variable aleatoria \\(X\\), entonces podemos fácilmente calcular la probabilidad que \\(X\\) pertenezca a un intervalo \\((a,b] \\subseteq \\mathbb{R}\\) como:\n\\[\\mathbb{P}(a<X<b)=F_X(b)-F_X(a)\\]"
  },
  {
    "objectID": "slides/lec_week6.html#valores-esperados",
    "href": "slides/lec_week6.html#valores-esperados",
    "title": "Variables aleatorias",
    "section": "Valores esperados",
    "text": "Valores esperados\nSea \\(X\\) una variable aleatoria, entonces se define el valor esperado de una función real \\(g(X)\\), como:\n\\[\\mathbb{E}[g(X)]= \\begin{cases} \\sum_{x\\in \\mathbb{R}} g(X)P(X=x)\\\\ \\int_{x\\in \\mathbb{R}} g(X)f(x)dx \\end{cases}\\]\nSi \\(g(X)=X\\), diremos que el valor esperado o esperanza matemática de \\(X\\) es:\n\\[\\mathbb{E}(X)=\\begin{cases}\\sum_{x\\in \\mathbb{R}} x P(X=x)\\\\ \\int_{x\\in \\mathbb{R}} x f(x)dx \\end{cases}\\]\nPara variables de tipo discreta y continua, respectivamente."
  },
  {
    "objectID": "slides/lec_week6.html#propiedades-de-los-valores-esperados",
    "href": "slides/lec_week6.html#propiedades-de-los-valores-esperados",
    "title": "Variables aleatorias",
    "section": "Propiedades de los valores esperados",
    "text": "Propiedades de los valores esperados\nSean \\(a\\) y \\(b\\) constantes, \\(X\\) una variable aleatoria entonces se cumple que:\n\n\\(\\mathbb{E}(a)=a\\)\n\\(\\mathbb{E}(X)=\\mu=\\) constante\n\\(\\mathbb{E}(aX)=a\\mathbb{E}(X)\\)\n\\(\\mathbb{E}(aX+b)=\\mathbb{E}(aX)+\\mathbb{E}(b)=a\\mathbb{E}(X)+b\\)"
  },
  {
    "objectID": "slides/lec_week6.html#varianza",
    "href": "slides/lec_week6.html#varianza",
    "title": "Variables aleatorias",
    "section": "Varianza",
    "text": "Varianza\nSea \\(X\\) una variable aleatoria, se define el la varianza de \\(X\\) como:\n\\[\\mathbb{E}[(X-\\mathbb{E}(X))^2]=V(X)=\\begin{cases}\\sum_{x\\in\\mathbb{R}} (X-\\mathbb{E}(X))^2P(X=x)\\\\ \\int_{x\\in\\mathbb{R}}(X-\\mathbb{E}(X))^2f_{X}(x)dx\\end{cases}\\]\nPara variables de tipo discreta y continua, respectivamente."
  },
  {
    "objectID": "slides/lec_week6.html#propiedades-de-la-varianza",
    "href": "slides/lec_week6.html#propiedades-de-la-varianza",
    "title": "Variables aleatorias",
    "section": "Propiedades de la varianza",
    "text": "Propiedades de la varianza\nSea \\(a\\) y \\(b\\) constantes, \\(X\\) una variable aleatoria, entonces se cumple:\n\n\\(\\mathbb{V}(a)=0\\)\n\\(\\mathbb{V}(X)=\\sigma^2=\\) constante\n\\(\\mathbb{V}(aX)=a^2 \\mathbb{V}(X)\\)\n\\(\\mathbb{V}(aX+b)=\\mathbb{V}(aX)+\\mathbb{V}(b)=a^2\\mathbb{V}(X)+0=a^2\\mathbb{V}(X)\\)\n\\(\\mathbb{V}(X)=\\mathbb{E}(X^2)-(\\mathbb{E}(X))^2\\)"
  },
  {
    "objectID": "slides/lec_week6.html#esperanza-y-varianza-condicional",
    "href": "slides/lec_week6.html#esperanza-y-varianza-condicional",
    "title": "Variables aleatorias",
    "section": "Esperanza y varianza condicional",
    "text": "Esperanza y varianza condicional\nSea \\(X\\) e \\(Y\\) variables aleatorias discretas. La esperanza condicional de \\(X\\) dado que \\(Y=y\\), donde \\(f_{Y}(y)>0\\), se define por:\n\\[\\mathbb{E}[X|Y=y]=\\sum_{x\\in\\mathbb{R}}x\\mathbb{P}(X=x|Y=y)= \\sum_{x\\in\\mathbb{R}} x \\dfrac{\\mathbb{P}(X=x,Y=y)}{\\mathbb{P}(Y=y)}\\]\nNotar que y toma todos los valores del recorrido de \\(Y\\)."
  },
  {
    "objectID": "slides/lec_week6.html#ejemplo-1",
    "href": "slides/lec_week6.html#ejemplo-1",
    "title": "Variables aleatorias",
    "section": "Ejemplo #1",
    "text": "Ejemplo #1\nSea \\(X\\) una variable aleatoria discreta que tiene la siguiente función de cuantía:\n\\[P_{X}(1)=\\dfrac{1}{2} \\hspace{30pt} P_{X}(2)=\\dfrac{1}{4} \\hspace{30pt} P_{X}(3)=\\dfrac{1}{8} \\hspace{30pt} P_{X}(4)=\\dfrac{1}{8}\\]\n\nEncontrar y graficar la función de distribución acumulada \\(F_{X}(x)\\) de la variable aleatoria \\(X\\).\nEncontrar \\(\\mathbb{P}(X\\leq1)\\), \\(\\mathbb{P}(1<X\\leq3)\\), \\(\\mathbb{P}(1\\leq X \\leq 3)\\)."
  },
  {
    "objectID": "slides/lec_week6.html#resolución-ejemplo-1",
    "href": "slides/lec_week6.html#resolución-ejemplo-1",
    "title": "Variables aleatorias",
    "section": "Resolución ejemplo #1",
    "text": "Resolución ejemplo #1\nLa función de distribución acumulado está dada por: \\[\\begin{align*}\nF_{X}(x)\n\\begin{cases}\n0 \\hspace{20pt} \\text{si } X< 1\\\\\n\\dfrac{1}{2} \\hspace{20pt} \\text{si } 1 \\leq X < 2  \\\\\n\\dfrac{1}{2}+\\dfrac{1}{4}=\\dfrac{3}{4} \\hspace{20pt} \\text{si } 2\\leq X < 3\\\\\n\\dfrac{3}{4}+\\dfrac{1}{8}=\\dfrac{7}{8} \\hspace{20pt} \\text{si } 3\\leq X < 4\\\\\n1 \\hspace{20pt} \\text{si } X \\geq  4\\\\\n\\end{cases}\n\\end{align*}\\] El gráfico de esta función es igual que graficar una función escalonada."
  },
  {
    "objectID": "slides/lec_week6.html#resolución-ejemplo-1-continuación",
    "href": "slides/lec_week6.html#resolución-ejemplo-1-continuación",
    "title": "Variables aleatorias",
    "section": "Resolución ejemplo #1: continuación",
    "text": "Resolución ejemplo #1: continuación\nLuego, usando la información dada por la función de distribución.\n\n\\(\\mathbb{P}(X\\leq 1)=F_{X}(1)=\\dfrac{1}{2}\\)\n\\(\\mathbb{P}(1<X\\leq 3)=\\mathbb{P}(X \\leq 3)-\\mathbb{P}(X \\leq 1)=F_{X}(3)-F_{X}(1)=\\dfrac{7}{8}-\\dfrac{1}{2}=\\dfrac{3}{8}\\)\n\\(\\mathbb{P}(1 \\leq X \\leq 3)=\\mathbb{P}(X\\leq 3)=\\dfrac{7}{8}\\)"
  },
  {
    "objectID": "slides/lec_week6.html#ejemplo-2",
    "href": "slides/lec_week6.html#ejemplo-2",
    "title": "Variables aleatorias",
    "section": "Ejemplo #2",
    "text": "Ejemplo #2\nConsiderar la variable aleatoria discreta \\(X\\) cuya función de cuantía está dada por:\n\\[\\begin{align*}\np_{X}(x)=\\begin{cases}\n\\dfrac{1}{3} \\hspace{20pt} x=-1,0,1\\\\\n0 \\hspace{20pt} e.o.c.\n\\end{cases}\n\\end{align*}\\]\n\n\nGraficar \\(p_{X}(x)\\) y encontrar la esperanza y varianza de X.\nRepetir lo anterior considerando la función de cuantía como:\n\n\n\n\\[\\begin{align*}\np_{X}(x)=\\begin{cases}\n\\dfrac{1}{3} \\hspace{20pt} x=-2,0,2\\\\\n0 \\hspace{20pt} e.o.c.\n\\end{cases}\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/lec_week6.html#resolución-ejemplo-2",
    "href": "slides/lec_week6.html#resolución-ejemplo-2",
    "title": "Variables aleatorias",
    "section": "Resolución ejemplo #2",
    "text": "Resolución ejemplo #2\nLa esperanza y varianza de la variable aleatoria \\(X\\) la podemos obtener por definición, en el primer caso: \\[\\begin{align*}\n\\mathbb{E}(X)&=-1\\cdot \\mathbb{P}(X=-1)+0\\cdot \\mathbb{P}(X=0)+1\\cdot \\mathbb{P}(X=1)\\\\\n&= -1 \\cdot \\dfrac{1}{3} + 0 + 1\\cdot \\dfrac{1}{3} = 0\\\\\n\\end{align*}\\] y la varianza está dada por: \\[\\begin{align*}\n\\mathbb{V}(X)&=\\mathbb{E}(X^2)-(\\mathbb{E}(X))^2=\\mathbb{E}(X^2)\\\\\n&= -1^2 \\cdot \\mathbb{P}(X=-1)+0\\cdot \\mathbb{P}(X=0)+1^2\\cdot \\mathbb{P}(X=1)\\\\\n&= \\dfrac{1}{3}+0+\\dfrac{1}{3}=\\dfrac{2}{3}\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/lec_week6.html#resolución-ejemplo-2-1",
    "href": "slides/lec_week6.html#resolución-ejemplo-2-1",
    "title": "Variables aleatorias",
    "section": "Resolución ejemplo #2",
    "text": "Resolución ejemplo #2\nAhora en el segundo caso: \\[\\begin{align*}\n\\mathbb{E}(X)&=-2\\cdot \\mathbb{P}(X=-2)+0\\cdot \\mathbb{P}(X=0)+2\\cdot \\mathbb{P}(X=2)\\\\\n&= -2 \\cdot \\dfrac{1}{3} + 0 + 2\\cdot \\dfrac{1}{3} = 0\\\\\n\\end{align*}\\] y la varianza está dada por: \\[\\begin{align*}\n\\mathbb{V}(X)&=\\mathbb{E}(X^2)-(\\mathbb{E}(X))^2=\\mathbb{E}(X^2)\\\\\n&= -2^2 \\cdot \\mathbb{P}(X=-1)+0\\cdot \\mathbb{P}(X=0)+2^2\\cdot \\mathbb{P}(X=1)\\\\\n&= \\dfrac{4}{3}+0+\\dfrac{4}{3}=\\dfrac{8}{3}\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/lec_week6.html#ejemplo-3",
    "href": "slides/lec_week6.html#ejemplo-3",
    "title": "Variables aleatorias",
    "section": "Ejemplo #3",
    "text": "Ejemplo #3\nConsidere el lanzamiento de 3 monedas con denominación de \\(1\\), \\(5\\) y \\(10\\) pesos, respectivamente. Sea \\(X\\) la suma de las monedas que caen cara.\n\n¿Cuál es el valor esperado de \\(X\\) dado que dos monedas caen cara?\nSea \\(Y\\) la suma de las monedas que caen cara, y que además, tienen denominación de \\(1\\) o \\(5\\) pesos. ¿Cuál es la esperanza condicional de \\(X\\) dado \\(Y\\)?"
  },
  {
    "objectID": "slides/lec_week6.html#resolución-ejemplo-3",
    "href": "slides/lec_week6.html#resolución-ejemplo-3",
    "title": "Variables aleatorias",
    "section": "Resolución ejemplo 3",
    "text": "Resolución ejemplo 3\nDefinamos primero el espacio muestral del experimento aleatorio:\n\\[\\Omega=\\{CCC,CCS,CSC,SCC,CSS,SCS,SSC,SSS\\}\\]\nSi definimos el evento \\(B\\) como el evento en que dos monedas caen cara, entonces:\n\\[B=\\{CCS,CSC,SCC\\}\\]\nNos interesa determinar el valor de \\(E(X|B)\\). Primero, notamos que cada punto del evento \\(B\\) tiene una probabilidad de ocurrencia de \\(\\dfrac{1}{8}\\). Luego, obtenemos los valores de la V.A. \\(X\\):\n\\[X(CCS)= 1+5=6, \\hspace{10pt} X(CSC)=1+10=11, \\hspace{10pt} X(SCC)=5+10=15\\]"
  },
  {
    "objectID": "slides/lec_week6.html#resolución-ejemplo-3-continuación",
    "href": "slides/lec_week6.html#resolución-ejemplo-3-continuación",
    "title": "Variables aleatorias",
    "section": "Resolución ejemplo 3: continuación",
    "text": "Resolución ejemplo 3: continuación\nLuego, calculamos \\(E(X|B)\\) por definición:\n\\[\\mathbb{E}(X|B)=\\dfrac{1}{3/8}\\left( 6 \\dfrac{1}{8}+11\\dfrac{1}{8}+15\\dfrac{1}{8}\\right)=\\dfrac{32}{3}\\]\nPara resolver el ítem b, observamos que \\(Y=\\{0,1,5,6\\}\\) con probabilidades:\n\\[\\mathbb{P}(Y=0)=\\mathbb{P}(Y=1)=\\mathbb{P}(Y=5)=\\mathbb{P}(Y=6)=\\dfrac{1}{4}\\]\nSiguiendo el mismo procedimiento que antes: \\[\\begin{align*}\n\\mathbb{E}(X|\\{Y=0\\})=5,\\hspace{10pt}\\mathbb{E}(X|\\{Y=1\\})=6\\\\\n\\mathbb{E}(X|\\{Y=5\\})=10,\\hspace{10pt}\\mathbb{E}(X|\\{Y=6\\})=11\\\\\n\\end{align*}\\] En donde \\(\\mathbb{E}(X|\\{Y=0\\})=\\dfrac{1}{1/4}\\left(\\dfrac{1}{8}\\overbrace{X(SSC)}^{10}+\\dfrac{1}{8}\\overbrace{X(SSS)}^{0}\\right)=5\\)"
  },
  {
    "objectID": "slides/lec_week6.html#resolución-ejemplo-3-1",
    "href": "slides/lec_week6.html#resolución-ejemplo-3-1",
    "title": "Variables aleatorias",
    "section": "Resolución ejemplo 3",
    "text": "Resolución ejemplo 3\nAsí, podemos expresar la esperanza condicional de \\(X\\) dado \\(Y\\) como: \\[\\begin{align*}\n\\mathbb{E}(X|Y)(\\omega)\n\\begin{cases}\n5 \\hspace{10pt}\\text{si } Y(\\omega)=0,\\\\\n6 \\hspace{10pt}\\text{si } Y(\\omega)=1,\\\\\n10 \\hspace{10pt}\\text{si } Y(\\omega)=5,\\\\\n11 \\hspace{10pt}\\text{si } Y(\\omega)=6.\\\\\n\\end{cases}\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/lec_week6.html#ejemplo-4",
    "href": "slides/lec_week6.html#ejemplo-4",
    "title": "Variables aleatorias",
    "section": "Ejemplo #4",
    "text": "Ejemplo #4\nUna variable aleatoria \\(X\\) tiene función de densidad:\n\\[\\begin{align*}\nf(x)=\n\\begin{cases}\n\\dfrac{c}{x^2+1} , & -\\infty < x < \\infty \\\\\n0 ,& e.o.c\\\\\n\\end{cases}\n\\end{align*}\\]\n\nHallar el valor de la constante c.\nHallar la probabilidad de que \\(X^2\\) esté entre \\(\\dfrac{1}{3}\\) y \\(1\\)."
  },
  {
    "objectID": "slides/lec_week6.html#resolución-ejemplo-4",
    "href": "slides/lec_week6.html#resolución-ejemplo-4",
    "title": "Variables aleatorias",
    "section": "Resolución ejemplo #4",
    "text": "Resolución ejemplo #4\nPara hallar el valor de la constante C, utilizamos las propiedades de la función de densidad: \\(\\int_{-\\infty}^{\\infty} f(x)dx=1\\). Así:\n\\[\\int_{-\\infty}^{\\infty} \\dfrac{c}{x^2+1}dx = c\\tan^{-1}\\Bigg\\vert_{-\\infty}^{\\infty}=c\\left[ \\dfrac{\\pi}{2}-(-\\dfrac{\\pi}{2})\\right]=1\\Rightarrow c=\\dfrac{1}{\\pi}\\]\nLuego, para hallar la probabilidad pedida en el item b:\n\\[\\text{Si } \\dfrac{1}{3}\\leq X^2 \\leq 1, \\text{ entonces } \\dfrac{\\sqrt{3}}{3}\\leq X \\leq 1 \\text{ o } -1 \\leq X \\leq -\\dfrac{\\sqrt{3}}{3}\\]\nPor lo que la probabilidad pedida está dada por:\n\\[\\dfrac{1}{\\pi}\\int_{-1}^{-\\dfrac{\\sqrt{3}}{3}}\\dfrac{dx}{x^2+1}+\\dfrac{1}{\\pi}\\int_{\\dfrac{\\sqrt{3}}{3}}^{1}\\dfrac{dx}{x^2+1}=\\dfrac{2}{\\pi}\\int_{\\dfrac{\\sqrt{3}}{3}}^{1} \\dfrac{dx}{x^2+1}=\\dfrac{1}{6}\\]"
  },
  {
    "objectID": "slides/lec_week6.html#momentos-de-una-variable-aleatoria",
    "href": "slides/lec_week6.html#momentos-de-una-variable-aleatoria",
    "title": "Variables aleatorias",
    "section": "Momentos de una variable aleatoria",
    "text": "Momentos de una variable aleatoria\nSean \\(X_1,X_2,\\cdots,X_n\\) una muestra aleatoria con función de masa de probabilidad \\(f_{X}\\). Entonces el \\(r\\)-ésimo momento poblacional en torno a cero se define por:\n\\[\\mu_r=\\mathbb{E}[X^r]\\]\ndonde se puede observar, que para el caso de \\(r=1\\), se obtiene la esperanza matemática."
  },
  {
    "objectID": "slides/lec_week6.html#distribución-binomial",
    "href": "slides/lec_week6.html#distribución-binomial",
    "title": "Variables aleatorias",
    "section": "Distribución binomial",
    "text": "Distribución binomial\nSea \\(X\\) una variable aleatoria que representa el número de éxitos en \\(n\\) ensayos y \\(p\\) la probabilidad de éxito con cualquiera de éstos. Se dice entonces que \\(X\\) tiene una distribución binomial con función de probabilidad:\n\\[\\mathbb{P}(X=k)= {{n}\\choose{k}}p^k(1-p)^{n-k} \\hspace{20pt} k=1,2,\\cdots,n\\]\nEn donde \\(\\displaystyle {{n}\\choose{k}}\\) es el coeficiente binomial, esto es:\n\\[\\displaystyle{{n}\\choose{k}}=\\dfrac{n!}{k!(n-k)!}\\]\nSi \\(n=1\\) diremos que \\(X\\) sigue una distribución Bernoulli."
  },
  {
    "objectID": "slides/lec_week6.html#distribución-binomial-propiedades",
    "href": "slides/lec_week6.html#distribución-binomial-propiedades",
    "title": "Variables aleatorias",
    "section": "Distribución binomial: propiedades",
    "text": "Distribución binomial: propiedades\nSi \\(X\\) tiene una distribución binomial, entonces se cumple que:\n\n\\(\\mathbb{E}[X]=np\\)\n\\(\\mathbb{V}[X]=np(1-p)\\)\n\n\nEs claro ver que si \\(X\\) tiene una distribución bernoulli, entonces:\n\n\\(\\mathbb{E}[X]=p\\)\n\\(\\mathbb{V}[X]=p(1-p)\\)"
  },
  {
    "objectID": "slides/lec_week6.html#distribución-binomial-gráfico",
    "href": "slides/lec_week6.html#distribución-binomial-gráfico",
    "title": "Variables aleatorias",
    "section": "Distribución binomial: gráfico",
    "text": "Distribución binomial: gráfico"
  },
  {
    "objectID": "slides/lec_week6.html#distribución-binomial-ejemplo",
    "href": "slides/lec_week6.html#distribución-binomial-ejemplo",
    "title": "Variables aleatorias",
    "section": "Distribución Binomial: ejemplo",
    "text": "Distribución Binomial: ejemplo\nDurante los últimos años, se ha logrado establecer que el 30% de los alumnos que ingresan por primera vez a cierta Universidad, reprueban todas las asignaturas de primer semestre. Si, en el segundo semestre, se elige al azar a 15 alumnos que ingresaron el semestre anterior a la Universidad.\n\n¿Cuál es la probabilidad que sólo 5 de ellos hayan reprobado todas las asignaturas del primer semestre?\n¿Cuál es la probabilidad que a lo más 13 hayan reprobado todas las asignaturas del primer semestre?\n¿Cuál es la probabilidad de que 8 o más hayan reprobado todas las asignaturas?"
  },
  {
    "objectID": "slides/lec_week6.html#resolución-ejemplo",
    "href": "slides/lec_week6.html#resolución-ejemplo",
    "title": "Variables aleatorias",
    "section": "Resolución ejemplo",
    "text": "Resolución ejemplo\nLo primero es reconocer que el contexto del problema es posible modelarlo mediante una distribución binomial: número de éxitos dada una probabilidad conocida. Sabemos que para calcular las probabilidades bajo este distribución es necesario saber dicha probabilidad de éxito \\(p\\). Por enunciado sabemos que \\(p=0.3\\) y \\(n=15\\). Luego, definimos la variable aleatoria:\n\\[\\begin{align*}\nX= \\text{N° de alumnos que reprueban todas las asignaturas al ingresar}\\\\\n\\text{ por 1ra vez a cierta Universidad.}\n\\end{align*}\\]\nAhora podemos calcular las probabilidad pedidas, de las cuales debemos reconocer:\n\n\n\\(\\mathbb{P}(X=5)=F_{X}(5)-F_{X}(4)=0.7216-0.5155=0.2061\\)\n\\(\\mathbb{P}(X\\leq 13)=F_{X}(13)\\approx 1\\)\n\\(\\mathbb{P}(X\\geq 8)=1-\\mathbb{P}(X<8)=1-\\mathbb{P}(X\\leq 7)=1-F_{X}(7)=1-0.9500=0.0173\\)\n\n\n\nUtilizamos la notación \\(X\\sim Bin(15,0.3)\\) para mostrar la distribución de la variable aleatoria."
  },
  {
    "objectID": "slides/lec_week6.html#distribución-de-poisson",
    "href": "slides/lec_week6.html#distribución-de-poisson",
    "title": "Variables aleatorias",
    "section": "Distribución de Poisson",
    "text": "Distribución de Poisson\nSea \\(X\\) una variable aleatoria que representa el número de eventos aleatorios independientes que ocurren a una rapidez constante sobre el tiempo o el espacio. Se dice entonces que la variable aleatoria \\(X\\) tiene una distribución de Poisson con función de probabilidad:\n\\[\\mathbb{P}(X=k)=\\dfrac{e^{-\\lambda}\\lambda^k}{k!} \\hspace{20pt} k=0,1,\\cdots,n,\\cdots\\]\nEn donde \\(\\lambda>0\\) representa el número promedio de ocurrencias del evento aleatorio por unidad de tiempo. Además, si \\(X\\) sigue una distribución de Poisson se cumple que:\n\n\\(\\mathbb{E}[X]=\\lambda\\)\n\\(\\mathbb{V}[X]=\\lambda\\)"
  },
  {
    "objectID": "slides/lec_week6.html#distribución-poisson-gráfico",
    "href": "slides/lec_week6.html#distribución-poisson-gráfico",
    "title": "Variables aleatorias",
    "section": "Distribución Poisson: gráfico",
    "text": "Distribución Poisson: gráfico"
  },
  {
    "objectID": "slides/lec_week6.html#distribución-de-poisson-ejemplo",
    "href": "slides/lec_week6.html#distribución-de-poisson-ejemplo",
    "title": "Variables aleatorias",
    "section": "Distribución de Poisson: Ejemplo",
    "text": "Distribución de Poisson: Ejemplo\nEn un estudio invernal de una tienda, se determinó que un articulo se pide en promedio cinco veces por semana (de 5 días), de acuerdo a una distribución Poisson. ¿Cuál es la probabilidad de que en un día especifico, el articulo.\n\nSe pida más de cinco veces.\nNo se pida."
  },
  {
    "objectID": "slides/lec_week6.html#resolución-ejemplo-5",
    "href": "slides/lec_week6.html#resolución-ejemplo-5",
    "title": "Variables aleatorias",
    "section": "Resolución ejemplo",
    "text": "Resolución ejemplo\nPara resolver este tipo de problemas, lo primero es reconocere que es posible modelar la variable aleatoria mediante una distribución de Poissión. Como la distribución de Poisson tiene un parámetros (\\(\\lambda\\)), este debe ser sabido para poder calcular las probabilidades. Por enunciado sabemos que la tasa de ocurrencia es 5 en una semana. Como siempre definimos la variable aleatoria antes de cualquier cálculo.\n\\[X= \\text{N° de artículos que se pide en una tienda en una semana dada.}\\]\nPor lo que, utilizando la notación adecuada: \\(X\\sim Poisson(5)\\)"
  },
  {
    "objectID": "slides/lec_week6.html#resolución-ejemplo-continuación",
    "href": "slides/lec_week6.html#resolución-ejemplo-continuación",
    "title": "Variables aleatorias",
    "section": "Resolución ejemplo: continuación",
    "text": "Resolución ejemplo: continuación\n\nNos pregunta la probabilidad que en un día específico se pida más de cinco veces. Nuestra información original (V.A. \\(X\\)) refiera a una semana, por lo que si definimos una nueva variable aleatoria como:\n\n\n\\[Y= \\text{N° de artículos que se pide en una tienda en un día dado.}\\]\nPodemos afirmar que \\(Y\\sim Poisson(1)\\), debido a que se asume una rapidez constante de ocurrencia. Así, lo pedido lo podemos escribir como \\(\\mathbb{P}(Y>5)\\) y calculamos:\n\\[\\mathbb{P}(Y>5)=1-\\mathbb{P}(Y\\leq 5)=1-0.9994=0.0006\\]\n\n\\(\\mathbb{P}(Y=0)=0.3679\\)"
  },
  {
    "objectID": "slides/lec_week6.html#distribución-geométrica",
    "href": "slides/lec_week6.html#distribución-geométrica",
    "title": "Variables aleatorias",
    "section": "Distribución geométrica",
    "text": "Distribución geométrica\nSea \\(X\\) una variable aleatoria que representa el número de fallas que ocurren antes de que se presente el primer éxito.Se dice entonces que la variable aleatoria \\(X\\) tiene una distribución geométrica con función de probabilidad:\n\\[\\mathbb{P}(X=k)=(1-p)^{k-1}p \\hspace{20pt} k=1,2,\\cdots\\]\nEn donde \\(p\\) es la probabilidad de éxito. Además, Si \\(X\\) sigue una distribución Geométrica, entonces se cumple que:\n\n\\(\\displaystyle \\mathbb{E}[X]=\\dfrac{1}{p}\\)\n\\(\\mathbb{V}[X]=\\dfrac{(1-p)}{p^2}\\)"
  },
  {
    "objectID": "slides/lec_week6.html#distribución-geométrica-gráfico",
    "href": "slides/lec_week6.html#distribución-geométrica-gráfico",
    "title": "Variables aleatorias",
    "section": "Distribución geométrica: gráfico",
    "text": "Distribución geométrica: gráfico"
  },
  {
    "objectID": "slides/lec_week6.html#distribución-hipergeométrica",
    "href": "slides/lec_week6.html#distribución-hipergeométrica",
    "title": "Variables aleatorias",
    "section": "Distribución hipergeométrica",
    "text": "Distribución hipergeométrica\nSea \\(N\\) el número total de objetos de una población finita, de manera tal que \\(k\\) de éstos es de un tipo y \\(N-k\\) de otros. Si se selecciona una muestra aleatoria de la población constituida por \\(n\\) objetos de la probabilidad de que \\(x\\) sea de un tipo exactamente y \\(n-x\\) sea del otro, está dada por la función de probabilidad hipergeométrica:\n\\[\\displaystyle \\mathbb{P}(X=x)= \\dfrac{           {{k}\\choose{x}} {{N-k}\\choose{n-x}}  }{  {{N}\\choose{n}}}\\hspace{20pt} x=1,2,\\cdots,n; x \\leq k, n-x\\leq N-k\\]\nSi \\(X\\) sigue una distribución Hipergeométrica, si \\(p=k/N\\)\n\n\\(\\mathbb{E}[X]=np\\)\n\\(\\mathbb{V}[X]=np(1-p)\\left( \\dfrac{N-n}{N-1}\\right)\\)"
  },
  {
    "objectID": "slides/lec_week6.html#distribución-hipergeométrica-gráfico",
    "href": "slides/lec_week6.html#distribución-hipergeométrica-gráfico",
    "title": "Variables aleatorias",
    "section": "Distribución hipergeométrica: gráfico",
    "text": "Distribución hipergeométrica: gráfico"
  },
  {
    "objectID": "slides/lec_week7.html#distribución-normal",
    "href": "slides/lec_week7.html#distribución-normal",
    "title": "Distribuciones continuas",
    "section": "Distribución normal",
    "text": "Distribución normal\nSea \\(X\\) una variable aleatoria que toma valores reales, esto es: \\(-\\infty<x<\\infty\\), diremos que \\(X\\) sigue una distribución normal (o Gaussiana) si su función de densidad está por:\n\\[f_{X}(x)=\\dfrac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left[ -\\dfrac{1}{2}\\left(\\dfrac{x-\\mu}{\\sigma}\\right) ^2\\right]\\]\nEn donde los parámetros de la distribución son \\(\\mu\\) y \\(\\sigma\\) satisfacen las condiciones:\n\\[\\begin{align*}\n-\\infty<\\mu<\\infty\\\\\n\\sigma^2>0\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/lec_week7.html#propiedades-de-la-distribución-normal",
    "href": "slides/lec_week7.html#propiedades-de-la-distribución-normal",
    "title": "Distribuciones continuas",
    "section": "Propiedades de la distribución normal",
    "text": "Propiedades de la distribución normal\nSi \\(X\\) sigue una distribución normal de parámetros \\(\\mu\\) y \\(\\sigma\\), entonces se cumple que:\n\n\\(\\mathbb{E}(X)=\\mu\\)\n\\(\\mathbb{V}(X)=E[X^2]-(E[X])^2=\\sigma^2\\)\nSi \\(Y=aX+b\\) entonces \\(Y\\) sigue una distribución normal de parámetros \\(a\\mu+b\\) y \\(a^2\\sigma^2\\), respectivamente. Se escribe: \\(Y \\sim N(a\\mu+b,a^2\\sigma^2)\\)"
  },
  {
    "objectID": "slides/lec_week7.html#densidad-de-la-distribución-normal",
    "href": "slides/lec_week7.html#densidad-de-la-distribución-normal",
    "title": "Distribuciones continuas",
    "section": "Densidad de la distribución normal",
    "text": "Densidad de la distribución normal"
  },
  {
    "objectID": "slides/lec_week7.html#ejemplo-distribución-normal",
    "href": "slides/lec_week7.html#ejemplo-distribución-normal",
    "title": "Distribuciones continuas",
    "section": "Ejemplo distribución Normal",
    "text": "Ejemplo distribución Normal\nLa duración de un láser semiconductor a potencia constante tiene una distribución normal con media 7.000 horas y desviación estándar de 600 horas.\n\n¿Cuál es la probabilidad de que el láser falle antes de 5.000 horas?\n¿Cuál es la duración en horas excedida por el 99% de los lasers?\nSi se hace uso de tres láser en un producto y se supone que fallan de manera independiente. ¿Cuál es la probabilidad de que los tres sigan funcionando después de 6700 horas?"
  },
  {
    "objectID": "slides/lec_week7.html#resolución-ejemplo",
    "href": "slides/lec_week7.html#resolución-ejemplo",
    "title": "Distribuciones continuas",
    "section": "Resolución ejemplo",
    "text": "Resolución ejemplo\nPor enunciado, sabemos que si definimos la variable aleatoria \\(X\\) como:\n\\[X= \\text{Duración de un laser semiconductor a potencia constante.}\\]\nEntonces, podemos afirmar que \\(X\\sim N(7000,600^2)\\). Luego,\n\\[\\begin{align*}\n\\mathbb{P}(X<5000)&=\\mathbb{P}\\left(\\dfrac{X-7000}{600} < \\dfrac{5000-7000}{600}\\right)\\\\\n&=\\mathbb{P}(Z< -3.333); \\hspace{10pt} Z\\sim N(0,1)\\\\\n&=0.0004\n\\end{align*}\\]\ny,\n\\[\\begin{align*}\n&\\mathbb{P}(X>x)=0.99 \\Rightarrow 1-\\mathbb{P}(X\\leq x)=0.99\\\\\n&\\mathbb{P}\\left(\\dfrac{X-7000}{600} \\leq \\dfrac{x-7000}{600}\\right)=\\mathbb{P}(Z\\leq z)=0.01\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/lec_week7.html#resolución-ejemplo-continuación",
    "href": "slides/lec_week7.html#resolución-ejemplo-continuación",
    "title": "Distribuciones continuas",
    "section": "Resolución ejemplo: continuación",
    "text": "Resolución ejemplo: continuación\n\\[\\mathbb{P}(Z\\leq z)=0.01 \\Rightarrow z=-2.325\\]\nAhora nos devolvemos a la variable original \\(X\\), así:\n\\[-2.325=\\dfrac{x-7000}{600} \\Rightarrow x=5605\\]\nPor lo que, la duración en horas excedida por el 99% de los lasers es de 5605 horas."
  },
  {
    "objectID": "slides/lec_week7.html#resolución-ejemplo-continuación-1",
    "href": "slides/lec_week7.html#resolución-ejemplo-continuación-1",
    "title": "Distribuciones continuas",
    "section": "Resolución ejemplo: continuación",
    "text": "Resolución ejemplo: continuación\nAhora, para el item c) debemos reconocer como modelar la variable aleatoria del problema. Definimos la variable aleatoria:\n\\[Y= \\text{ N° de lasers que siguen funcionando después de 6700 hrs}\\]\nDebimos reconocer que esta variable aleatoria tiene distribución \\(Bin(3,p)\\) en donde \\(p\\) es la probabilidad que uno de los lasers siga funcionando después de 6700 horas. Por lo que primero calculamos este valor:\n\\[\\begin{align*}\n\\mathbb{P}(X>6700)&=1-\\mathbb{P}(X\\leq 6700)=1-\\mathbb{P}\\left(\\dfrac{X-7000}{600} < \\dfrac{6700-7000}{600}\\right)\\\\\n&=1-\\mathbb{P}(Z<-0.5)=1-.3085=0.6915\n\\end{align*}\\]\nAsí, \\(Y\\sim Bin(3,0.6915)\\). Finalmente, lo preguntado lo planteamos como:\n\\[\\mathbb{P}(Y=3)=\\mathbb{P}(Y\\leq 3)-\\mathbb{P}(Y\\leq 2)= 1- 0.657 = 0.343\\]"
  },
  {
    "objectID": "slides/lec_week7.html#distribución-uniforme",
    "href": "slides/lec_week7.html#distribución-uniforme",
    "title": "Distribuciones continuas",
    "section": "Distribución Uniforme",
    "text": "Distribución Uniforme\nSea \\(X\\) una variable aleatoria continua, diremos que \\(X\\) sigue una distribución uniforme sobre el intervalo \\((a,b)\\) si su función de densidad de probabilidad está dada por:\n\\[\\begin{align*}\nf_{X}(x)=\\begin{cases}\n1/(b-a) \\hspace{20pt} a\\leq x \\leq b\\\\\n0 \\hspace{20pt} e.o.c\n\\end{cases}\n\\end{align*}\\]\nLos parámetros de la distribución cumplen las condiciones:\n\\[-\\infty<a<\\infty, \\quad  -\\infty<b<\\infty\\]\n\n\\(\\mathbb{E}(X)=\\dfrac{(a+b)}{2}\\)\n\\(\\mathbb{V}(X)=\\dfrac{(b-a)^2}{12}\\)"
  },
  {
    "objectID": "slides/lec_week7.html#densidad-de-la-distribución-uniforme",
    "href": "slides/lec_week7.html#densidad-de-la-distribución-uniforme",
    "title": "Distribuciones continuas",
    "section": "Densidad de la distribución uniforme",
    "text": "Densidad de la distribución uniforme"
  },
  {
    "objectID": "slides/lec_week7.html#distribución-exponencial",
    "href": "slides/lec_week7.html#distribución-exponencial",
    "title": "Distribuciones continuas",
    "section": "Distribución exponencial",
    "text": "Distribución exponencial\nSea \\(X\\) una variable aleatoria continua que toma valores positivos, diremos que \\(X\\) sigue una distribución exponencial con parámetro \\(\\alpha>0\\) si su función de densidad está dada por:\n\\[\\begin{align*}\nf_{X}(x)=\\begin{cases}\n\\alpha e^{-\\alpha x} \\hspace{20pt} x\\geq 0 \\\\\n0 \\hspace{20pt} e.o.c\n\\end{cases}\n\\end{align*}\\]\nAdemás se cumple que:\n\n\\(\\mathbb{E}(X)=\\dfrac{1}{\\alpha}\\)\n\\(\\mathbb{V}(X)=\\dfrac{1}{\\alpha^2}\\)"
  },
  {
    "objectID": "slides/lec_week7.html#densidad-de-la-distribución-exponencial",
    "href": "slides/lec_week7.html#densidad-de-la-distribución-exponencial",
    "title": "Distribuciones continuas",
    "section": "Densidad de la distribución exponencial",
    "text": "Densidad de la distribución exponencial"
  },
  {
    "objectID": "slides/lec_week7.html#función-gamma",
    "href": "slides/lec_week7.html#función-gamma",
    "title": "Distribuciones continuas",
    "section": "Función gamma",
    "text": "Función gamma\nLa función Gamma denotada por \\(\\Gamma\\) está definida por:\n\\[\\Gamma(p)=\\int_{0}^{\\infty} x^{p-1} e^{-x}dx \\hspace{20pt} p>0\\]\nEsta función cumple las siguientes propiedades:\n\n\\(\\Gamma(n)=(n-1)!\\)\n\\(\\Gamma(1/2)=\\sqrt{\\pi}\\)"
  },
  {
    "objectID": "slides/lec_week7.html#distribución-gamma",
    "href": "slides/lec_week7.html#distribución-gamma",
    "title": "Distribuciones continuas",
    "section": "Distribución gamma",
    "text": "Distribución gamma\nSea \\(X\\) una variable aleatoria continua que toma valores positivos. Diremos que \\(X\\) sigue una distribución Gamma si su función de densidad está dada por:\n\\[\\begin{align*}\nf_{X}(x)=\\begin{cases}\n\\dfrac{\\alpha}{\\Gamma(r)}(\\alpha x)^{r-1}e^{-\\alpha x} \\hspace{20pt} x>0\\\\\n0 \\hspace{20pt} e.o.c\n\\end{cases}\n\\end{align*}\\]\nEn donde los parámetros \\(r\\) y \\(\\alpha\\) son positivos.\nEs claro ver que un caso particular de la distribución Gamma es la distribución exponencial (\\(r=1\\)). Si \\(X\\) se distribuye Gamma entonces se cumple:\n\n\\(\\mathbb{E}(X)=r/\\alpha\\)\n\\(\\mathbb{V}(X)=r/\\alpha^2\\)"
  },
  {
    "objectID": "slides/lec_week7.html#densidad-de-la-distribución-gamma",
    "href": "slides/lec_week7.html#densidad-de-la-distribución-gamma",
    "title": "Distribuciones continuas",
    "section": "Densidad de la distribución gamma",
    "text": "Densidad de la distribución gamma"
  },
  {
    "objectID": "slides/lec_week7.html#distribución-chi-cuadrado",
    "href": "slides/lec_week7.html#distribución-chi-cuadrado",
    "title": "Distribuciones continuas",
    "section": "Distribución chi-cuadrado",
    "text": "Distribución chi-cuadrado\nSea \\(X\\) una variable aleatoria continua que toma valores positivos, diremos que \\(X\\) sigue una distribución chi-cuadrado con \\(k\\) grados de libertad, si su función de densidad de probabilidad está dada por:\n\\[f(x;k)=\n\\begin{cases}\\displaystyle\n\\frac{1}{2^{k/2}\\Gamma(k/2)}\\,x^{(k/2) - 1} e^{-x/2}&\\text{para }x>0,\\\\\n0&\\text{para }x\\le0\n\\end{cases}\\] donde \\(\\Gamma\\) es la función gamma. Si \\(X\\) se distribuye Chi-Cuadrado entonces:\n\n\\(\\mathbb{E}[X]=k\\)\n\\(\\mathbb{V}[X]=2k\\)"
  },
  {
    "objectID": "slides/lec_week7.html#densidad-de-la-distribución-chi-cuadrado",
    "href": "slides/lec_week7.html#densidad-de-la-distribución-chi-cuadrado",
    "title": "Distribuciones continuas",
    "section": "Densidad de la distribución chi-cuadrado",
    "text": "Densidad de la distribución chi-cuadrado"
  },
  {
    "objectID": "slides/lec_week7.html#distribución-t-student",
    "href": "slides/lec_week7.html#distribución-t-student",
    "title": "Distribuciones continuas",
    "section": "Distribución t-student",
    "text": "Distribución t-student\nSea \\(X\\) una variable aleatoria continua que toma valores reales, diremos que \\(X\\) sigue una distribución t-student con \\(\\nu\\) grados de libertad, si su función de densidad de probabilidad está dada por:\n\\[f(t) = \\frac{\\Gamma(\\frac{\\nu+1}{2})} {\\sqrt{\\nu\\pi}\\,\\Gamma(\\frac{\\nu}{2})} \\left(1+\\frac{t^2}{\\nu} \\right)^{\\!-\\frac{\\nu+1}{2}},\\!\\]\ndonde \\(\\Gamma\\) es la función gamma. Si \\(X\\) se distribuye t-student entonces:\n\n\\(\\mathbb{E}[X]=0\\) para \\(\\nu>1\\). Indefinida para otros valores.\n\\(\\mathbb{V}[X]=\\dfrac{\\nu}{\\nu -2}\\) para \\(\\nu>2\\). Indefinida para otros valores."
  },
  {
    "objectID": "slides/lec_week7.html#densidad-de-la-distribución-t-student",
    "href": "slides/lec_week7.html#densidad-de-la-distribución-t-student",
    "title": "Distribuciones continuas",
    "section": "Densidad de la distribución t-student",
    "text": "Densidad de la distribución t-student"
  },
  {
    "objectID": "slides/lec_week7.html#distribuciones-de-probabilidad-bivariada-continuación",
    "href": "slides/lec_week7.html#distribuciones-de-probabilidad-bivariada-continuación",
    "title": "Distribuciones continuas",
    "section": "Distribuciones de probabilidad bivariada: continuación",
    "text": "Distribuciones de probabilidad bivariada: continuación\nAnálogamente que en distribuciones univariadas, la función de distribución acumulada bivariada es la probabilidad conjunto de que \\(X\\leq x\\), y \\(Y\\leq y\\), dada por:\n\\[F_{X,Y}(x,y)=\\mathbb{P}(X \\leq x, Y \\leq y)=\\sum_{x_i \\leq x} \\sum_{y_i \\leq y} p(x_i,y_i)\\]\nLa función de probabilidad conjunta de dos variables aleatorias da origen a las probabilidad puntuales conjuntas, y la función de distribución bivariada es una función escalonada creciente para cada probabilidad puntual distinta de cero, de manera tal que \\(X=x\\) e \\(Y=y\\)."
  },
  {
    "objectID": "slides/lec_week7.html#distribuciones-de-probabilidad-bivariada-continuación-1",
    "href": "slides/lec_week7.html#distribuciones-de-probabilidad-bivariada-continuación-1",
    "title": "Distribuciones continuas",
    "section": "Distribuciones de probabilidad bivariada: continuación",
    "text": "Distribuciones de probabilidad bivariada: continuación\nDe igual manera, es posible definir lo anterior para variables aleatorias continuas. Sean \\(X\\) e \\(Y\\) dos variables aleatorias continuas. Si existe una función \\(f(x,y)\\) tal que la probabilidad conjunta:\n\\[\\mathbb{P}(a<X<b,c<Y<d)=\\int_{a}^{b}\\int_{c}^{d}f(x,y)dydx\\]\npara cualquier valor de \\(a,b,c\\) y \\(d\\) en donde \\(f(x,y)\\geq 0\\), \\(-\\infty < x,y < \\infty\\) y,\n\\[\\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} f(x,y)dydx =1,\\]\nentonces \\(f(x,y)\\) es la función de densidad de probabilidad bivariada de \\(X\\) e \\(Y\\)."
  },
  {
    "objectID": "slides/lec_week7.html#distribuciones-de-probabilidad-bivariada-continuación-2",
    "href": "slides/lec_week7.html#distribuciones-de-probabilidad-bivariada-continuación-2",
    "title": "Distribuciones continuas",
    "section": "Distribuciones de probabilidad bivariada: continuación",
    "text": "Distribuciones de probabilidad bivariada: continuación\nLa función de distribución bivariada acumulada de \\(X\\) e \\(Y\\) es la probabilidad conjunta de que \\(X\\leq x\\) y \\(Y\\leq y\\), dada por:\n\\[\\mathbb{P}(X \\leq x , Y \\leq y)=F(x,y)=\\int_{-\\infty}^{x} \\int_{-\\infty}^{y} f(u,v)dv,du\\]\nAsí, la función de densidad bivariadad se encuentra diferenciando \\(F(x,y)\\) con respecto a \\(x\\) e \\(y\\), es decir:\n\\[f(x,y)=\\dfrac{\\partial^2 F(x,y)}{\\partial x \\partial y}\\]"
  },
  {
    "objectID": "slides/lec_week7.html#distribuciones-marginales-de-probabilidad",
    "href": "slides/lec_week7.html#distribuciones-marginales-de-probabilidad",
    "title": "Distribuciones continuas",
    "section": "Distribuciones marginales de probabilidad",
    "text": "Distribuciones marginales de probabilidad\nSean \\(X\\) e \\(Y\\) dos variables aleatorias discretas con una función de probabilidad conjunta \\(p(x,y)\\). Las funciones marginales de probabilidad de \\(X\\) e \\(Y\\) están dadas por:\n\\[p_X(x)=\\sum_{y} p(x,y)\\]\ny,\n\\[p_Y(y)=\\sum_{x} p(x,y),\\]\nrespectivamente."
  },
  {
    "objectID": "slides/lec_week7.html#distribuciones-marginales-de-probabilidad-1",
    "href": "slides/lec_week7.html#distribuciones-marginales-de-probabilidad-1",
    "title": "Distribuciones continuas",
    "section": "Distribuciones marginales de probabilidad",
    "text": "Distribuciones marginales de probabilidad\nSean \\(X\\) e \\(Y\\) dos variables aleatorias continuas con una función de densidad de probabilidad conjunta \\(f(x,y)\\). Las funciones de densidad de probabilidad de \\(X\\) E \\(Y\\) están dadas por:\n\\[f_X(x)=\\int_{-\\infty}^{x}f(x,y)dy\\]\ny,\n\\[f_Y(y)=\\int_{-\\infty}^{y}f(x,y)dx\\]"
  },
  {
    "objectID": "slides/lec_week7.html#distribuciones-marginales-de-probabilidad-continuación",
    "href": "slides/lec_week7.html#distribuciones-marginales-de-probabilidad-continuación",
    "title": "Distribuciones continuas",
    "section": "Distribuciones marginales de probabilidad: continuación",
    "text": "Distribuciones marginales de probabilidad: continuación\nPara variables aleatorias continuas conjuntas, si se conoce la función de distribución acumulada \\(F(x,y)\\), las distribuciones acumuladas marginales de \\(X\\) e \\(Y\\) se obtienen de la siguiente forma:\n\\[\\mathbb{P}(X\\leq x)=F_X(x)=\\int_{-\\infty}^{x} \\int_{-\\infty}^{\\infty} f(t,y)dydt\\]\ny,\n\\[F_X(x)=\\int_{-\\infty}^{x} f_X(t)dt=F(x,\\infty)\\]\nDe manera similar,\n\\[\\mathbb{P}(Y\\leq y)=F_Y(y)=\\int_{-\\infty}^{y} \\int_{-\\infty}^{\\infty} f(x,t)dydt\\]"
  },
  {
    "objectID": "slides/lec_week7.html#valores-esperados-y-momentos-para-distribuciones-bivariadas",
    "href": "slides/lec_week7.html#valores-esperados-y-momentos-para-distribuciones-bivariadas",
    "title": "Distribuciones continuas",
    "section": "Valores esperados y momentos para distribuciones bivariadas",
    "text": "Valores esperados y momentos para distribuciones bivariadas\nSean \\(X\\) e \\(Y\\) dos variables aleatorias que se distribuyen conjuntamente. El valor esperado de una función de \\(X\\) y de \\(Y\\), \\(g(x,y)\\) se define como:\n\\[\\mathbb{E}(g(X,Y))=\\sum_{x} \\sum_y g(x,y)p(x,y)\\]\nsi \\(X\\) e \\(Y\\) son V.A. discretas, o\n\\[\\mathbb{E}(g(X,Y))=\\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} g(x,y) f(x,y) dydx\\]\nsi \\(X\\) e \\(Y\\) son continuas, en donde \\(p(x,y)\\) y \\(f(x,y)\\) son las funciones de probabilidad y de densidad de probabilidad conjuntas, respectivamente."
  },
  {
    "objectID": "slides/lec_week7.html#momentos-para-distribuciones-bivariadas",
    "href": "slides/lec_week7.html#momentos-para-distribuciones-bivariadas",
    "title": "Distribuciones continuas",
    "section": "Momentos para distribuciones bivariadas",
    "text": "Momentos para distribuciones bivariadas\nEl \\(r-\\)ésimo momento de \\(X\\) alrededor del cero es:\n\\[\\mathbb{E}(X^r)=\\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} x^r f(x,y)dydx=\\int_{-\\infty}^{\\infty}x^r f_X(x)dx\\]\nPor lo que el \\(r\\) y \\(s-\\)ésimo momento producto de \\(X\\) e \\(Y\\) alrededor del origen es:\n\\[\\mathbb{E}(X^r Y^s)=\\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} x^r y^s f(x,y)dydx\\]\ny alrededor de las medias es:\n\\[\\mathbb{E}((X-\\mu_X)^r(Y-\\mu_Y)^s)=\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}(x-\\mu_X)^r(y-\\mu_Y)^sf(x,y)dydx\\]\nen donde \\(r\\) y \\(s\\) son enteros, no negativos."
  },
  {
    "objectID": "slides/lec_week7.html#momentos-para-distribuciones-bivariadas-continuación",
    "href": "slides/lec_week7.html#momentos-para-distribuciones-bivariadas-continuación",
    "title": "Distribuciones continuas",
    "section": "Momentos para distribuciones bivariadas: continuación",
    "text": "Momentos para distribuciones bivariadas: continuación\nEs de particular importancia el momento producto alrededor de las medias cuando \\(r=s=1\\). Este momento producto recibe el nombre de covarianza de \\(X\\) e \\(Y\\), y se encuentra definido por:\n\\[COV(X,Y)=\\mathbb{E}((X-\\mu_X)(Y-\\mu_Y))\\]\nAl igual que la varianza, que es una medida de dispersión de una variable aleatoria, la covarianza es una medida de variabilidad conjunta de \\(X\\) y de \\(Y\\). De esta forma, la covarianza es una medida de asociación entre los valores de \\(X\\) y de \\(Y\\) y sus respectivas dispersiones. La expresión anterior puede ser reescrita de la forma:\n\\[COV(X,Y)=\\mathbb{E}(XY)-\\mathbb{E}(X)\\mathbb{E}(Y)\\]"
  },
  {
    "objectID": "slides/lec_week7.html#momentos-para-distribuciones-bivariadas-continuación-1",
    "href": "slides/lec_week7.html#momentos-para-distribuciones-bivariadas-continuación-1",
    "title": "Distribuciones continuas",
    "section": "Momentos para distribuciones bivariadas: continuación",
    "text": "Momentos para distribuciones bivariadas: continuación\nSi la covarianza de \\(X\\) y de \\(Y\\) se divide por el producto de las desviaciones estándar de \\(X\\) y de \\(Y\\), el resultado es una cantidad sin dimensiones que recibe el nombre de coeficiente de correlación y que se denota por \\(\\rho(X,Y)\\), esto es:\n\\[\\rho(X,Y)=\\dfrac{COV(X,Y)}{\\sigma_x \\sigma_y}\\]\nSe puede demostrar que el coeficiente de correlación \\(\\rho \\in [-1,1]\\)"
  },
  {
    "objectID": "slides/lec_week7.html#variables-aleatorias-independientes",
    "href": "slides/lec_week7.html#variables-aleatorias-independientes",
    "title": "Distribuciones continuas",
    "section": "Variables aleatorias independientes",
    "text": "Variables aleatorias independientes\nSean \\(X\\) e \\(Y\\) dos variables aleatorias con una distribución conjunta. Se dice que \\(X\\) e \\(Y\\) son estadísticamente independientes sí y sólo si,\n\\[p(x,y)=p_X(x)p_Y(y)\\hspace{20pt} \\text{ Si X e Y son discretas}\\]\no bien,\n\\[f(x,y)=f_X(x)f_Y(y)\\hspace{20pt} \\text{ Si X e Y son continuas}\\]\npara toda \\(x\\) e \\(y\\), en donde \\(p(x,y)\\) y \\(f(x,y)\\) son las funciones bivariadas de probabilidad y de densidad de probabilidad, respectivamente."
  },
  {
    "objectID": "slides/lec_week7.html#variables-aleatorias-independientes-continuación",
    "href": "slides/lec_week7.html#variables-aleatorias-independientes-continuación",
    "title": "Distribuciones continuas",
    "section": "Variables aleatorias independientes: continuación",
    "text": "Variables aleatorias independientes: continuación\nSe desprende de la definición anterior que si \\(X\\) e \\(Y\\) son V.A. independientes, la probabilidad conjunta:\n\\[\\mathbb{P}(a<X<b,c<Y<d)=\\mathbb{P}(a<X<b)\\mathbb{P}(c<Y<d)\\]\ny por lo anterior,\n\\[\\mathbb{E}(XY)=\\mathbb{E}(X)\\mathbb{E}(Y)\\]\nY si \\(X\\) e \\(Y\\) son V.A. independientes, entonces \\(COV(X,Y)=\\rho(X,Y)=0\\),mas no el converso no es necesariamente cierto."
  },
  {
    "objectID": "slides/lec_week7.html#distribuciones-de-probabilidad-condicional",
    "href": "slides/lec_week7.html#distribuciones-de-probabilidad-condicional",
    "title": "Distribuciones continuas",
    "section": "Distribuciones de probabilidad condicional",
    "text": "Distribuciones de probabilidad condicional\nSean \\(X\\) e \\(Y\\) dos variables aleatorias con una función de densidad conjunta de probabilidad \\(f(x,y)\\). La función de densidad de probabilidad condicional de la variable aleatoria \\(X\\), denotada por \\(f(x|y)\\), para un valor fijo \\(y\\) de \\(Y\\), está definida por:\n\\[f(x|y)=\\dfrac{f(x,y)}{f_Y(y)}\\]\nen donde \\(f_Y(y)\\) es la función de densidad marginal de \\(Y\\) de manera tal que \\(f_Y(y)>0\\). Es claro ver que bajo independencia de estas variables aleatorias, se tiene:\n\\[f(x|y)=f_X(x)\\]"
  },
  {
    "objectID": "slides/lec_week7.html#distribuciones-de-probabilidad-condicional-continuación",
    "href": "slides/lec_week7.html#distribuciones-de-probabilidad-condicional-continuación",
    "title": "Distribuciones continuas",
    "section": "Distribuciones de probabilidad condicional: continuación",
    "text": "Distribuciones de probabilidad condicional: continuación\nLos valores esperados se definen de manera análoga a lo visto anteriormente, esto es:\n\\[\\mathbb{E}(X|y)=\\int_{-\\infty}^{\\infty}xf(x|y)dx\\]\ny,\n\\[\\mathbb{E}(Y|x)=\\int_{-\\infty}^{\\infty}yf(y|x)dy\\]"
  },
  {
    "objectID": "slides/lec_week7.html#ejemplo",
    "href": "slides/lec_week7.html#ejemplo",
    "title": "Distribuciones continuas",
    "section": "Ejemplo",
    "text": "Ejemplo\nLa función de probabilidad conjunta de dos variables aleatorias discretas \\(X, Y\\) está dada por \\(f(x,y) = c(2x+y)\\), donde \\(x,y\\) pueden tomar todos los valores enteros tales que \\(0\\leq x \\leq 2,0\\leq y \\leq 3\\), y \\(f(x,y)=0\\) de otra forma.\n\nHallar el valor de la constante c\nHallar \\(\\mathbb{P}(X=2,Y=1)\\)\nHallar \\(\\mathbb{P}(X\\geq 1, Y\\leq 2)\\)"
  },
  {
    "objectID": "slides/lec_week7.html#resolución-ejemplo-1",
    "href": "slides/lec_week7.html#resolución-ejemplo-1",
    "title": "Distribuciones continuas",
    "section": "Resolución ejemplo",
    "text": "Resolución ejemplo\nNotamos que las V.A. toman sólo los valores entero, por lo que c lo obtenemos como:\n\\[\\begin{align*}\n\\sum_{x=0}^{2}\\sum_{y=0}^{3} c(2x+y)=1\n\\end{align*}\\]\nPodemos resumir los valores que toma la función de cuantía como:\n\nPor lo que \\(c=\\dfrac{1}{42}\\)"
  },
  {
    "objectID": "slides/lec_week7.html#resolución-ejemplo-continuación-2",
    "href": "slides/lec_week7.html#resolución-ejemplo-continuación-2",
    "title": "Distribuciones continuas",
    "section": "Resolución ejemplo: continuación",
    "text": "Resolución ejemplo: continuación\nPara el ítem 2. \\(\\mathbb{P}(X=2,Y=3)\\) basta notar la celda correspondiente en la tabla construida reemplazando c apropiadamente, por lo que \\(\\mathbb{P}(X=2,Y=3)=7c=\\dfrac{7}{42}\\)\nPara el ítem 3. Reconocemos que:\n\\[\\begin{align*}\n\\mathbb{P}(X\\geq 1,Y\\leq 2)&=\\mathbb{P}(X=1,Y=0)+\\mathbb{P}(X=2,Y=0)\\\\\n&+\\mathbb{P}(X=1,Y=1)+\\mathbb{P}(X=2,Y=1)\\\\\n&+\\mathbb{P}(X=1,Y=2)+\\mathbb{P}(X=2,Y=2)\\\\\n&=2c+4c+3c+5c+4c+6c=24c=\\dfrac{24}{42}\n\\end{align*}\\]"
  },
  {
    "objectID": "pages/week8.html",
    "href": "pages/week8.html",
    "title": "Semana 8",
    "section": "",
    "text": "Estudiar pruebas de años anteriores\nDesarrollar guía de ejercicios\nLeer capítulo 6 y 7, Probability and Statistics for Engineering and the Sciences, 9th Edition."
  }
]